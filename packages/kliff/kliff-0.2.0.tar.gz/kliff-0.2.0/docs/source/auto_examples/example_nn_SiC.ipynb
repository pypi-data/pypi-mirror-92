{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Train a neural network potential for SiC\n\nIn this tutorial, we train a neural network (NN) potential for a system containing two\nspecies: Si and C. This is very similar to the training for systems containing a single\nspecie (take a look at `tut_nn` for Si if you haven't yet).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from kliff import nn\nfrom kliff.calculators.calculator_torch import CalculatorTorchSeparateSpecies\nfrom kliff.dataset import Dataset\nfrom kliff.descriptors import SymmetryFunction\nfrom kliff.loss import Loss\nfrom kliff.models import NeuralNetwork\nfrom kliff.utils import download_dataset\n\ndescriptor = SymmetryFunction(\n    cut_name=\"cos\",\n    cut_dists={\"Si-Si\": 5.0, \"C-C\": 5.0, \"Si-C\": 5.0},\n    hyperparams=\"set51\",\n    normalize=True,\n)\n\nN1 = 10\nN2 = 10\nmodel_si = NeuralNetwork(descriptor)\nmodel_si.add_layers(\n    # first hidden layer\n    nn.Linear(descriptor.get_size(), N1),\n    nn.Tanh(),\n    # second hidden layer\n    nn.Linear(N1, N2),\n    nn.Tanh(),\n    # output layer\n    nn.Linear(N2, 1),\n)\nmodel_si.set_save_metadata(prefix=\"./kliff_saved_model_si\", start=5, frequency=2)\n\n\nN1 = 10\nN2 = 10\nmodel_c = NeuralNetwork(descriptor)\nmodel_c.add_layers(\n    # first hidden layer\n    nn.Linear(descriptor.get_size(), N1),\n    nn.Tanh(),\n    # second hidden layer\n    nn.Linear(N1, N2),\n    nn.Tanh(),\n    # output layer\n    nn.Linear(N2, 1),\n)\nmodel_c.set_save_metadata(prefix=\"./kliff_saved_model_c\", start=5, frequency=2)\n\n\n# training set\ndataset_path = download_dataset(dataset_name=\"SiC_training_set\")\ntset = Dataset(dataset_path)\nconfigs = tset.get_configs()\n\n# calculator\ncalc = CalculatorTorchSeparateSpecies({\"Si\": model_si, \"C\": model_c})\ncalc.create(configs, reuse=False)\n\n# loss\nloss = Loss(calc, residual_data={\"forces_weight\": 0.3})\nresult = loss.minimize(method=\"Adam\", num_epochs=10, batch_size=4, lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can save the trained model to disk, and later can load it back if we want. We can\nalso write the trained model to a KIM model such that it can be used in other simulation\ncodes such as LAMMPS via the KIM API.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_si.save(\"final_model_si.pkl\")\nmodel_c.save(\"final_model_c.pkl\")\nloss.save_optimizer_state(\"optimizer_stat.pkl\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}