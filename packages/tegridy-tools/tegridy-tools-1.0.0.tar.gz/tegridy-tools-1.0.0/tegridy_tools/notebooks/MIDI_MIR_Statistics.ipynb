{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIDI_MIR_Statistics.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-KvtvAuHB75"
      },
      "source": [
        "# MIDI MIR Statistics Notebook (ver 1.0)\r\n",
        "\r\n",
        "***\r\n",
        "\r\n",
        "## View detailed info and stats for the specified MIDI file\r\n",
        "\r\n",
        "***\r\n",
        "\r\n",
        "#### Project Los Angeles\r\n",
        "#### Tegridy Code 2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JAn6JXOJQNw",
        "cellView": "form"
      },
      "source": [
        "#@title Install all dependencies\n",
        "!git clone https://github.com/asigalov61/tegridy-tools\n",
        "!pip install mido\n",
        "!pip install visual_midi\n",
        "!pip install pypianoroll\n",
        "!git clone https://github.com/sniperwrb/python-midi\n",
        "!apt-get install swig\n",
        "%cd /content/python-midi\n",
        "!python setup.py install\n",
        "%cd /content/\n",
        "!mkdir /content/midis/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_HTRvgRDMTK",
        "cellView": "form"
      },
      "source": [
        "#@title Import needed modules\n",
        "import os\n",
        "import numpy as np\n",
        "import mido\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from matplotlib.colors import colorConverter\n",
        "\n",
        "import sys, math, time\n",
        "\n",
        "import midi\n",
        "\n",
        "from pypianoroll import Multitrack, Track\n",
        "\n",
        "from mido import MidiFile\n",
        "from operator import itemgetter\n",
        "\n",
        "from visual_midi import Plotter\n",
        "from visual_midi import Preset\n",
        "from pretty_midi import PrettyMIDI\n",
        "\n",
        "\n",
        "import midi\n",
        "from midi.constants import NOTE_NAME_MAP_SHARP\n",
        "import argparse\n",
        "import networkx as nx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "034LPUFVEO2i",
        "cellView": "form"
      },
      "source": [
        "#@title Specify the input MIDI file to analyze\n",
        "MIDI_file_to_analyze = \"/content/tegridy-tools/tegridy-tools/seed.mid\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "aU0jdqPs6pA2"
      },
      "source": [
        "#@title visual_midi Bokeh Plot\n",
        "preset = Preset(plot_width=850)\n",
        "plotter = Plotter(preset, plot_max_length_bar=4)\n",
        "pm = PrettyMIDI(MIDI_file_to_analyze)\n",
        "plotter.show_notebook(pm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Q_Ep6ZVE_oBO"
      },
      "source": [
        "#@title Plot Piano Roll\n",
        "# inherit the origin mido class\n",
        "class MidiFile(mido.MidiFile):\n",
        "\n",
        "    def __init__(self, filename):\n",
        "\n",
        "        mido.MidiFile.__init__(self, filename)\n",
        "        self.sr = 10\n",
        "        self.meta = {}\n",
        "        self.events = self.get_events()\n",
        "\n",
        "    def get_events(self):\n",
        "        mid = self\n",
        "        print(mid)\n",
        "\n",
        "        # There is > 16 channel in midi.tracks. However there is only 16 channel related to \"music\" events.\n",
        "        # We store music events of 16 channel in the list \"events\" with form [[ch1],[ch2]....[ch16]]\n",
        "        # Lyrics and meta data used a extra channel which is not include in \"events\"\n",
        "\n",
        "        events = [[] for x in range(16)]\n",
        "\n",
        "        # Iterate all event in the midi and extract to 16 channel form\n",
        "        for track in mid.tracks:\n",
        "            for msg in track:\n",
        "                try:\n",
        "                    channel = msg.channel\n",
        "                    events[channel].append(msg)\n",
        "                except AttributeError:\n",
        "                    try:\n",
        "                        if type(msg) != type(mido.UnknownMetaMessage):\n",
        "                            self.meta[msg.type] = msg.dict()\n",
        "                        else:\n",
        "                            pass\n",
        "                    except:\n",
        "                        print(\"error\",type(msg))\n",
        "\n",
        "        return events\n",
        "\n",
        "    def get_roll(self):\n",
        "        events = self.get_events()\n",
        "        # Identify events, then translate to piano roll\n",
        "        # choose a sample ratio(sr) to down-sample through time axis\n",
        "        sr = self.sr\n",
        "\n",
        "        # compute total length in tick unit\n",
        "        length = self.get_total_ticks()\n",
        "\n",
        "        # allocate memory to numpy array\n",
        "        roll = np.zeros((16, 128, length // sr), dtype=\"int8\")\n",
        "\n",
        "        # use a register array to save the state(no/off) for each key\n",
        "        note_register = [int(-1) for x in range(128)]\n",
        "\n",
        "        # use a register array to save the state(program_change) for each channel\n",
        "        timbre_register = [1 for x in range(16)]\n",
        "\n",
        "\n",
        "        for idx, channel in enumerate(events):\n",
        "\n",
        "            time_counter = 0\n",
        "            volume = 100\n",
        "            # Volume would change by control change event (cc) cc7 & cc11\n",
        "            # Volume 0-100 is mapped to 0-127\n",
        "\n",
        "            print(\"channel\", idx, \"start\")\n",
        "            for msg in channel:\n",
        "                if msg.type == \"control_change\":\n",
        "                    if msg.control == 7:\n",
        "                        volume = msg.value\n",
        "                        # directly assign volume\n",
        "                    if msg.control == 11:\n",
        "                        volume = volume * msg.value // 127\n",
        "                        # change volume by percentage\n",
        "                    # print(\"cc\", msg.control, msg.value, \"duration\", msg.time)\n",
        "\n",
        "                if msg.type == \"program_change\":\n",
        "                    timbre_register[idx] = msg.program\n",
        "                    #print(\"channel\", idx, \"pc\", msg.program, \"time\", time_counter, \"duration\", msg.time)\n",
        "\n",
        "\n",
        "\n",
        "                if msg.type == \"note_on\":\n",
        "                    #print(\"on \", msg.note, \"time\", time_counter, \"duration\", msg.time, \"velocity\", msg.velocity)\n",
        "                    note_on_start_time = time_counter // sr\n",
        "                    note_on_end_time = (time_counter + msg.time) // sr\n",
        "                    intensity = volume * msg.velocity // 127\n",
        "\n",
        "\n",
        "\n",
        "\t\t\t\t\t# When a note_on event *ends* the note start to be play \n",
        "\t\t\t\t\t# Record end time of note_on event if there is no value in register\n",
        "\t\t\t\t\t# When note_off event happens, we fill in the color\n",
        "                    if note_register[msg.note] == -1:\n",
        "                        note_register[msg.note] = (note_on_end_time,intensity)\n",
        "                    else:\n",
        "\t\t\t\t\t# When note_on event happens again, we also fill in the color\n",
        "                        old_end_time = note_register[msg.note][0]\n",
        "                        old_intensity = note_register[msg.note][1]\n",
        "                        roll[idx, msg.note, old_end_time: note_on_end_time] = old_intensity\n",
        "                        note_register[msg.note] = (note_on_end_time,intensity)\n",
        "\n",
        "\n",
        "                if msg.type == \"note_off\":\n",
        "                  try:\n",
        "                    #print(\"off\", msg.note, \"time\", time_counter, \"duration\", msg.time, \"velocity\", msg.velocity)\n",
        "                    note_off_start_time = time_counter // sr\n",
        "                    note_off_end_time = (time_counter + msg.time) // sr\n",
        "                    note_on_end_time = note_register[msg.note][0]\n",
        "                    intensity = note_register[msg.note][1]\n",
        "\t\t\t\t\t# fill in color\n",
        "                    roll[idx, msg.note, note_on_end_time:note_off_end_time] = intensity\n",
        "\n",
        "                    note_register[msg.note] = -1  # reinitialize register\n",
        "                  except:\n",
        "                    continue\n",
        "                time_counter += msg.time\n",
        "\n",
        "                # TODO : velocity -> done, but not verified\n",
        "                # TODO: Pitch wheel\n",
        "                # TODO: Channel - > Program Changed / Timbre catagory\n",
        "                # TODO: real time scale of roll\n",
        "\n",
        "            # if there is a note not closed at the end of a channel, close it\n",
        "            for key, data in enumerate(note_register):\n",
        "                if data != -1:\n",
        "                    note_on_end_time = data[0]\n",
        "                    intensity = data[1]\n",
        "                    # print(key, note_on_end_time)\n",
        "                    note_off_start_time = time_counter // sr\n",
        "                    roll[idx, key, note_on_end_time:] = intensity\n",
        "                note_register[idx] = -1\n",
        "\n",
        "        return roll\n",
        "\n",
        "    def get_roll_image(self):\n",
        "        roll = self.get_roll()\n",
        "        plt.ioff()\n",
        "\n",
        "        K = 16\n",
        "\n",
        "        transparent = colorConverter.to_rgba('black')\n",
        "        colors = [mpl.colors.to_rgba(mpl.colors.hsv_to_rgb((i / K, 1, 1)), alpha=1) for i in range(K)]\n",
        "        cmaps = [mpl.colors.LinearSegmentedColormap.from_list('my_cmap', [transparent, colors[i]], 128) for i in\n",
        "                 range(K)]\n",
        "\n",
        "        for i in range(K):\n",
        "            cmaps[i]._init()  # create the _lut array, with rgba values\n",
        "            # create your alpha array and fill the colormap with them.\n",
        "            # here it is progressive, but you can create whathever you want\n",
        "            alphas = np.linspace(0, 1, cmaps[i].N + 3)\n",
        "            cmaps[i]._lut[:, -1] = alphas\n",
        "\n",
        "        fig = plt.figure(figsize=(12, 9))\n",
        "        a1 = fig.add_subplot(111)\n",
        "        a1.axis(\"equal\")\n",
        "        a1.set_facecolor(\"black\")\n",
        "\n",
        "        array = []\n",
        "\n",
        "        for i in range(K):\n",
        "            try:\n",
        "                img = a1.imshow(roll[i], interpolation='nearest', cmap=cmaps[i], aspect='auto')\n",
        "                array.append(img.get_array())\n",
        "            except IndexError:\n",
        "                pass\n",
        "        return array\n",
        "\n",
        "    def draw_roll(self):\n",
        "\n",
        "\n",
        "        roll = self.get_roll()\n",
        "\n",
        "        # build and set fig obj\n",
        "        plt.ioff()\n",
        "        fig = plt.figure(figsize=(12, 9))\n",
        "        a1 = fig.add_subplot(111)\n",
        "        a1.axis(\"equal\")\n",
        "        a1.set_facecolor(\"black\")\n",
        "\n",
        "        # change unit of time axis from tick to second\n",
        "        tick = self.get_total_ticks()\n",
        "        second = mido.tick2second(tick, self.ticks_per_beat, self.get_tempo())\n",
        "        #print(second)\n",
        "        if second > 10:\n",
        "            x_label_period_sec = second // 10\n",
        "        else:\n",
        "            x_label_period_sec = second / 10  # ms\n",
        "        #print(x_label_period_sec)\n",
        "        x_label_interval = mido.second2tick(x_label_period_sec, self.ticks_per_beat, self.get_tempo()) / self.sr\n",
        "        #print(x_label_interval)\n",
        "        plt.xticks([int(x * x_label_interval) for x in range(20)], [round(x * x_label_period_sec, 2) for x in range(20)])\n",
        "\n",
        "        # change scale and label of y axis\n",
        "        plt.yticks([y*16 for y in range(8)], [y*16 for y in range(8)])\n",
        "\n",
        "        # build colors\n",
        "        channel_nb = 16\n",
        "        transparent = colorConverter.to_rgba('black')\n",
        "        colors = [mpl.colors.to_rgba(mpl.colors.hsv_to_rgb((i / channel_nb, 1, 1)), alpha=1) for i in range(channel_nb)]\n",
        "        cmaps = [mpl.colors.LinearSegmentedColormap.from_list('my_cmap', [transparent, colors[i]], 128) for i in\n",
        "                 range(channel_nb)]\n",
        "\n",
        "        # build color maps\n",
        "        for i in range(channel_nb):\n",
        "            cmaps[i]._init()\n",
        "            # create your alpha array and fill the colormap with them.\n",
        "            alphas = np.linspace(0, 1, cmaps[i].N + 3)\n",
        "            # create the _lut array, with rgba values\n",
        "            cmaps[i]._lut[:, -1] = alphas\n",
        "\n",
        "\n",
        "        # draw piano roll and stack image on a1\n",
        "        for i in range(channel_nb):\n",
        "            try:\n",
        "                a1.imshow(roll[i], origin=\"lower\", interpolation='nearest', cmap=cmaps[i], aspect='auto')\n",
        "            except IndexError:\n",
        "                pass\n",
        "\n",
        "        # draw color bar\n",
        "\n",
        "        colors = [mpl.colors.hsv_to_rgb((i / channel_nb, 1, 1)) for i in range(channel_nb)]\n",
        "        cmap = mpl.colors.LinearSegmentedColormap.from_list('my_cmap', colors, 16)\n",
        "        a2 = fig.add_axes([0.05, 0.80, 0.9, 0.15])\n",
        "        cbar = mpl.colorbar.ColorbarBase(a2, cmap=cmap,\n",
        "                                        orientation='horizontal',\n",
        "                                        ticks=list(range(16)))\n",
        "\n",
        "        # show piano roll\n",
        "        plt.draw()\n",
        "        plt.ion()\n",
        "        plt.show(block=True)\n",
        "        #plt.savefig('test.jpg', dpi=300)\n",
        "\n",
        "    def get_tempo(self):\n",
        "        try:\n",
        "            return self.meta[\"set_tempo\"][\"tempo\"]\n",
        "        except:\n",
        "            return 500000\n",
        "\n",
        "    def get_total_ticks(self):\n",
        "        max_ticks = 0\n",
        "        for channel in range(16):\n",
        "            ticks = sum(msg.time for msg in self.events[channel])\n",
        "            if ticks > max_ticks:\n",
        "                max_ticks = ticks\n",
        "        return max_ticks\n",
        "\n",
        "\n",
        "mid = MidiFile(MIDI_file_to_analyze)\n",
        "\n",
        "# get the list of all events\n",
        "# events = mid.get_events()\n",
        "\n",
        "# get the np array of piano roll image\n",
        "roll = mid.get_roll()\n",
        "\n",
        "# draw piano roll by pyplot\n",
        "mid.draw_roll()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bpy0cZB9JMpZ",
        "cellView": "form"
      },
      "source": [
        "#@title MIDI Stats 1\n",
        "\n",
        "# https://github.com/LiuFang816/SALSTM_py_data/blob/d494b3041069d377d6a7a9c296a14334f2fa5acc/python/olofmogren_c-rnn-gan/c-rnn-gan-master/midi_statistics.py\n",
        "# https://github.com/gbramleysimmons/musictransformers\n",
        "\n",
        "def msg2dict(msg):\n",
        "    result = dict()\n",
        "    if 'note_on' in msg:\n",
        "        on_ = True\n",
        "    elif 'note_off' in msg:\n",
        "        on_ = False\n",
        "    else:\n",
        "        on_ = None\n",
        "    result['time'] = int(msg[msg.rfind('time'):].split(' ')[0].split('=')[1].translate(\n",
        "        str.maketrans({a: None for a in string.punctuation})))\n",
        "\n",
        "    if on_ is not None:\n",
        "        for k in ['note', 'velocity']:\n",
        "            result[k] = int(msg[msg.rfind(k):].split(' ')[0].split('=')[1].translate(\n",
        "                str.maketrans({a: None for a in string.punctuation})))\n",
        "    return [result, on_]\n",
        "\n",
        "\n",
        "def switch_note(last_state, note, velocity, on_=True):\n",
        "    # piano has 88 notes, corresponding to note id 21 to 108, any note out of this range will be ignored\n",
        "    result = [0] * 88 if last_state is None else last_state.copy()\n",
        "    if 21 <= note <= 108:\n",
        "        result[note-21] = velocity if on_ else 0\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_new_state(new_msg, last_state):\n",
        "    new_msg, on_ = msg2dict(str(new_msg))\n",
        "    new_state = switch_note(last_state, note=new_msg['note'], velocity=new_msg['velocity'], on_=on_) if on_ is not None else last_state\n",
        "    return [new_state, new_msg['time']]\n",
        "\n",
        "\n",
        "def track2seq(track):\n",
        "    # piano has 88 notes, corresponding to note id 21 to 108, any note out of the id range will be ignored\n",
        "    result = []\n",
        "    last_state, last_time = get_new_state(str(track[0]), [0]*88)\n",
        "    for i in range(1, len(track)):\n",
        "        new_state, new_time = get_new_state(track[i], last_state)\n",
        "        if new_time > 0:\n",
        "            result += [last_state]*new_time\n",
        "        last_state, last_time = new_state, new_time\n",
        "    return result\n",
        "\n",
        "\n",
        "def mid2arry(mid, min_msg_pct=0.1):\n",
        "    tracks_len = [len(tr) for tr in mid.tracks]\n",
        "    min_n_msg = max(tracks_len) * min_msg_pct\n",
        "    # convert each track to nested list\n",
        "    all_arys = []\n",
        "    for i in range(len(mid.tracks)):\n",
        "        if len(mid.tracks[i]) > min_n_msg:\n",
        "            ary_i = track2seq(mid.tracks[i])\n",
        "            all_arys.append(ary_i)\n",
        "    # make all nested list the same length\n",
        "    max_len = max([len(ary) for ary in all_arys])\n",
        "    for i in range(len(all_arys)):\n",
        "        if len(all_arys[i]) < max_len:\n",
        "            all_arys[i] += [[0] * 88] * (max_len - len(all_arys[i]))\n",
        "    all_arys = np.array(all_arys)\n",
        "    all_arys = all_arys.max(axis=0)\n",
        "    # trim: remove consecutive 0s in the beginning and at the end\n",
        "    sums = all_arys.sum(axis=1)\n",
        "    ends = np.where(sums > 0)[0]\n",
        "    return all_arys[min(ends): max(ends)]\n",
        "\n",
        "\n",
        "def print_array(midi_array):\n",
        "    \n",
        "    plt.plot(range(midi_array.shape[0]), np.multiply(np.where(midi_array > 0, 1, 0), range(1, 89)), marker='.',\n",
        "             markersize=1, linestyle='')\n",
        "    #plt.show()\n",
        "    plt.savefig('MIDI Stats Graph.png', dpi=300)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Need to change filepath to midi path\n",
        "    filepath = MIDI_file_to_analyze\n",
        "    midi_file = mido.MidiFile(filepath, clip=True)\n",
        "    midi_array = mid2arry(midi_file)\n",
        "    print_array(midi_array)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7SDdWMwKu3G",
        "cellView": "form"
      },
      "source": [
        "#@title MIDI Stats 2\n",
        "# Tools to load and save midi files for the rnn-gan-project.\n",
        "# https://github.com/LiuFang816/SALSTM_py_data/blob/d494b3041069d377d6a7a9c296a14334f2fa5acc/python/olofmogren_c-rnn-gan/c-rnn-gan-master/midi_statistics.py\n",
        "# \n",
        "# https://github.com/TimStroup/Classical-Music-Generator/blob/847a410acb7e993c33e2116af45a7ccdb6b1a9e9/midi_statistics.py\n",
        "#\n",
        "# Written by Olof Mogren, http://mogren.one/\n",
        "#\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "GENRE      = 0\n",
        "COMPOSER   = 1\n",
        "SONG_DATA  = 2\n",
        "\n",
        "# INDICES IN BATCHES:\n",
        "LENGTH     = 0\n",
        "FREQ       = 1\n",
        "VELOCITY   = 2\n",
        "TICKS_FROM_PREV_START      = 3\n",
        "\n",
        "# INDICES IN SONG DATA (NOT YET BATCHED):\n",
        "BEGIN_TICK = 3\n",
        "CHANNEL    = 4\n",
        "\n",
        "debug = ''\n",
        "#debug = 'overfit'\n",
        "\n",
        "\n",
        "base_tones = {'C':   0,\n",
        "              'C#':  1, \n",
        "              'D':   2,\n",
        "              'D#':  3,\n",
        "              'E':   4,\n",
        "              'F':   5,\n",
        "              'F#':  6,\n",
        "              'G':   7,\n",
        "              'G#':  8,\n",
        "              'A':   9,\n",
        "              'A#': 10,\n",
        "              'B':  11}\n",
        "\n",
        "scale = {}\n",
        "#Major scale:\n",
        "scale['major'] = [0,2,4,5,7,9,11]\n",
        "#(W-W-H-W-W-W-H)\n",
        "#(2 2 1 2 2 2 1)\n",
        "\n",
        "#Natural minor scale:\n",
        "scale['natural_minor'] = [0,2,3,5,7,8,10]\n",
        "#(W-H-W-W-H-W-W)\n",
        "#(2 1 2 2 1 2 2)\n",
        " \n",
        "#Harmonic minor scale:\n",
        "scale['harmonic_minor'] = [0,2,3,5,7,8,11]\n",
        "#(W-H-W-W-H-WH-H)\n",
        "#(2 1 2 2 1 3 1)\n",
        "\n",
        "tone_names = {}\n",
        "for tone_name in base_tones:\n",
        "  tone_names[base_tones[tone_name]] = tone_name\n",
        "\n",
        "\n",
        "def get_tones(midi_pattern):\n",
        "  \"\"\"\n",
        "  returns a dict of statistics, keys: [scale_distribution,\n",
        "  \"\"\"\n",
        "  \n",
        "  tones = []\n",
        "  \n",
        "  for track in midi_pattern:\n",
        "    for event in track:\n",
        "      if type(event) == midi.events.SetTempoEvent:\n",
        "        pass # These are currently ignored\n",
        "      elif (type(event) == midi.events.NoteOffEvent) or \\\n",
        "           (type(event) == midi.events.NoteOnEvent and \\\n",
        "            event.velocity == 0):\n",
        "        pass # not needed here\n",
        "      elif type(event) == midi.events.NoteOnEvent:\n",
        "        tones.append(event.data[0])\n",
        "  return tones \n",
        "\n",
        "def detect_beat(midi_pattern):\n",
        "  \"\"\"\n",
        "  returns a dict of statistics, keys: [scale_distribution,\n",
        "  \"\"\"\n",
        "  \n",
        "  abs_ticks = []\n",
        "  \n",
        "  # Tempo:\n",
        "  ticks_per_quarter_note = float(midi_pattern.resolution)\n",
        "  \n",
        "  for track in midi_pattern:\n",
        "    abs_tick=0\n",
        "    for event in track:\n",
        "      abs_tick += event.tick\n",
        "      if type(event) == midi.events.SetTempoEvent:\n",
        "        pass # These are currently ignored\n",
        "      elif (type(event) == midi.events.NoteOffEvent) or \\\n",
        "           (type(event) == midi.events.NoteOnEvent and \\\n",
        "            event.velocity == 0):\n",
        "        pass\n",
        "      elif type(event) == midi.events.NoteOnEvent:\n",
        "        abs_ticks.append(abs_tick)\n",
        "  stats = {}\n",
        "  for quarter_note_estimate in range(int(ticks_per_quarter_note), int(0.75*ticks_per_quarter_note), -1):\n",
        "    #print('est: {}'.format(quarter_note_estimate))\n",
        "    avg_ticks_off = []\n",
        "    for begin_tick in range(quarter_note_estimate):\n",
        "      ticks_off = []\n",
        "      for abs_tick in abs_ticks:\n",
        "        #print('abs_tick: {} % {}'.format(abs_tick, quarter_note_estimate/4))\n",
        "        sixteenth_note_estimate = quarter_note_estimate/4\n",
        "        ticks_off_sixteenths = int((begin_tick+abs_tick)%sixteenth_note_estimate)\n",
        "        if ticks_off_sixteenths > sixteenth_note_estimate/2:\n",
        "          # off, but before beat \n",
        "          ticks_off_sixteenths = -(ticks_off_sixteenths-sixteenth_note_estimate)\n",
        "        #print('ticks_off: {}'.format(ticks_off_sixteenths))\n",
        "        ticks_off.append(ticks_off_sixteenths)\n",
        "      avg_ticks_off.append(float(sum(ticks_off))/float(len(ticks_off)))\n",
        "      #print('avg_ticks_off: {}. min: {}.'.format(avg_ticks_off, min(avg_ticks_off)))\n",
        "    stats[quarter_note_estimate] = min(avg_ticks_off)\n",
        "  return stats\n",
        "\n",
        "def get_abs_ticks(midi_pattern):\n",
        "  abs_ticks = []\n",
        "  for track in midi_pattern:\n",
        "    abs_tick=0\n",
        "    for event in track:\n",
        "      abs_tick += event.tick\n",
        "      if type(event) == midi.events.SetTempoEvent:\n",
        "        pass # These are currently ignored\n",
        "      elif (type(event) == midi.events.NoteOffEvent) or \\\n",
        "           (type(event) == midi.events.NoteOnEvent and \\\n",
        "            event.velocity == 0):\n",
        "        pass\n",
        "      elif type(event) == midi.events.NoteOnEvent:\n",
        "        abs_ticks.append(abs_tick)\n",
        "  abs_ticks.sort()\n",
        "  return abs_ticks\n",
        "\n",
        "def get_top_k_intervals(midi_pattern, k):\n",
        "  \"\"\"\n",
        "  returns a fraction of the noteon events in midi_pattern that are polyphonous\n",
        "  (several notes occurring at the same time).\n",
        "  Here, two note on events are counted as the same event if they\n",
        "  occur at the same time, and in this case it is considered a polyphonous event.\n",
        "  \"\"\"\n",
        "  intervals = {}\n",
        "  abs_ticks = get_abs_ticks(midi_pattern)\n",
        "  accumulator = 0\n",
        "  last_abs_tick = 0\n",
        "  for abs_tick in abs_ticks:\n",
        "    interval = abs_tick-last_abs_tick\n",
        "    if interval not in intervals:\n",
        "      intervals[interval] = 0\n",
        "    intervals[interval] += 1\n",
        "    accumulator += 1\n",
        "    last_abs_tick = abs_tick\n",
        "  intervals_list = [(interval, intervals[interval]/float(accumulator)) for interval in intervals]\n",
        "  intervals_list.sort(key=lambda i: i[1], reverse=True)\n",
        "  return intervals_list[:k]\n",
        "\n",
        "\n",
        "def get_polyphony_score(midi_pattern):\n",
        "  \"\"\"\n",
        "  returns a fraction of the noteon events in midi_pattern that are polyphonous\n",
        "  (several notes occurring at the same time).\n",
        "  Here, two note on events are counted as the same event if they\n",
        "  occur at the same time, and in this case it is considered a polyphonous event.\n",
        "  \"\"\"\n",
        "  \n",
        "  abs_ticks = get_abs_ticks(midi_pattern)\n",
        "  monophonous_events = 0\n",
        "  polyphonous_events = 0\n",
        "  \n",
        "  last_abs_tick = 0\n",
        "  tones_in_current_event = 0\n",
        "  for abs_tick in abs_ticks:\n",
        "    if abs_tick == last_abs_tick:\n",
        "      tones_in_current_event += 1\n",
        "    else:\n",
        "      if tones_in_current_event == 1:\n",
        "        monophonous_events += 1\n",
        "      elif tones_in_current_event > 1:\n",
        "        polyphonous_events += 1\n",
        "      tones_in_current_event = 1\n",
        "    last_abs_tick = abs_tick\n",
        "    if tones_in_current_event == 1:\n",
        "      monophonous_events += 1\n",
        "    elif tones_in_current_event > 1:\n",
        "      polyphonous_events += 1\n",
        "  if polyphonous_events == 0:\n",
        "    return 0.0\n",
        "  return float(polyphonous_events)/(polyphonous_events+monophonous_events)\n",
        "\n",
        "\n",
        "def get_rhythm_stats(midi_pattern):\n",
        "  \"\"\"\n",
        "  returns a dict of statistics, keys: [scale_distribution,\n",
        "  \"\"\"\n",
        "  \n",
        "  abs_ticks = []\n",
        "  \n",
        "  # Tempo:\n",
        "  ticks_per_quarter_note = float(midi_pattern.resolution)\n",
        "  \n",
        "  # Multiply with output_ticks_pr_input_tick for output ticks.\n",
        "  for track in midi_pattern:\n",
        "    abs_tick=0\n",
        "    for event in track:\n",
        "      abs_tick += event.tick\n",
        "      if type(event) == midi.events.SetTempoEvent:\n",
        "        pass # These are currently ignored\n",
        "      elif (type(event) == midi.events.NoteOffEvent) or \\\n",
        "           (type(event) == midi.events.NoteOnEvent and \\\n",
        "            event.velocity == 0):\n",
        "        pass\n",
        "      elif type(event) == midi.events.NoteOnEvent:\n",
        "        abs_ticks.append(abs_tick)\n",
        "  stats = {}\n",
        "  for abs_tick in abs_ticks:\n",
        "    ticks_since_quarter_note = int(abs_tick%ticks_per_quarter_note)\n",
        "    if ticks_since_quarter_note not in stats:\n",
        "      stats[ticks_since_quarter_note] = 1\n",
        "    else:\n",
        "      stats[ticks_since_quarter_note] += 1\n",
        "  return stats\n",
        "\n",
        "\n",
        "def get_intensities(midi_pattern):\n",
        "  \"\"\"\n",
        "  returns a dict of statistics, keys: [scale_distribution,\n",
        "  \"\"\"\n",
        "  \n",
        "  intensities = []\n",
        "  \n",
        "  for track in midi_pattern:\n",
        "    abs_tick=0\n",
        "    for event in track:\n",
        "      abs_tick += event.tick\n",
        "      if type(event) == midi.events.SetTempoEvent:\n",
        "        pass # These are currently ignored\n",
        "      elif (type(event) == midi.events.NoteOffEvent) or \\\n",
        "           (type(event) == midi.events.NoteOnEvent and \\\n",
        "            event.velocity == 0):\n",
        "        pass\n",
        "      elif type(event) == midi.events.NoteOnEvent:\n",
        "        intensities.append(event.velocity)\n",
        "  return (min(intensities), max(intensities))\n",
        "\n",
        "\n",
        "def get_midi_pattern(filename):\n",
        "  try:\n",
        "    return midi.read_midifile(filename)\n",
        "  except:\n",
        "    print ('Error reading {}'.format(filename))\n",
        "    return None\n",
        "\n",
        "def tones_to_scales(tones):\n",
        "  \"\"\"\n",
        "   Midi to tone name (octave: -5):\n",
        "   0: C\n",
        "   1: C#\n",
        "   2: D\n",
        "   3: D#\n",
        "   4: E\n",
        "   5: F\n",
        "   6: F#\n",
        "   7: G\n",
        "   8: G#\n",
        "   9: A\n",
        "   10: A#\n",
        "   11: B\n",
        "   Melodic minor scale is ignored.\n",
        "   One octave is 12 tones.\n",
        "  \"\"\"\n",
        "  counts = {}\n",
        "  for base_tone in base_tones:\n",
        "    counts[base_tone] = {}\n",
        "    counts[base_tone]['major'] = 0\n",
        "    counts[base_tone]['natural_minor'] = 0\n",
        "    counts[base_tone]['harmonic_minor'] = 0\n",
        "\n",
        "  if not len(tones):\n",
        "    frequencies = {}\n",
        "    for base_tone in base_tones:\n",
        "      frequencies[base_tone] = {}\n",
        "      for scale_label in scale:\n",
        "        frequencies[base_tone][scale_label] = 0.0\n",
        "    return frequencies\n",
        "  for tone in tones:\n",
        "    for base_tone in base_tones:\n",
        "      for scale_label in scale:\n",
        "        if tone%12-base_tones[base_tone] in scale[scale_label]:\n",
        "          counts[base_tone][scale_label] += 1\n",
        "  frequencies = {}\n",
        "  for base_tone in counts:\n",
        "    frequencies[base_tone] = {}\n",
        "    for scale_label in counts[base_tone]:\n",
        "      frequencies[base_tone][scale_label] = float(counts[base_tone][scale_label])/float(len(tones))\n",
        "  return frequencies\n",
        "\n",
        "def repetitions(tones):\n",
        "  rs = {}\n",
        "  #print(tones)\n",
        "  #print(len(tones)/2)\n",
        "  for l in range(2, min(len(tones)/2, 10)):\n",
        "    #print (l)\n",
        "    rs[l] = 0\n",
        "    for i in range(len(tones)-l*2):\n",
        "      for j in range(i+l,len(tones)-l):\n",
        "        #print('comparing \\'{}\\' and \\'{}\\''.format(tones[i:i+l], tones[j:j+l]))\n",
        "        if tones[i:i+l] == tones[j:j+l]:\n",
        "          rs[l] += 1\n",
        "  rs2 = {}\n",
        "  for r in rs:\n",
        "    if rs[r]:\n",
        "      rs2[r] = rs[r]\n",
        "  return rs2\n",
        "      \n",
        "\n",
        "def tone_to_tone_name(tone):\n",
        "  \"\"\"\n",
        "   Midi to tone name (octave: -5):\n",
        "   0: C\n",
        "   1: C#\n",
        "   2: D\n",
        "   3: D#\n",
        "   4: E\n",
        "   5: F\n",
        "   6: F#\n",
        "   7: G\n",
        "   8: G#\n",
        "   9: A\n",
        "   10: A#\n",
        "   11: B\n",
        "   One octave is 12 tones.\n",
        "  \"\"\"\n",
        "\n",
        "  base_tone = tone_names[tone%12]\n",
        "  octave = tone/12-5\n",
        "  return '{} {}'.format(base_tone, octave)\n",
        "\n",
        "def max_likelihood_scale(tones):\n",
        "  scale_statistics = tones_to_scales(tones) \n",
        "  stat_list = []\n",
        "  for base_tone in scale_statistics:\n",
        "    for scale_label in scale_statistics[base_tone]:\n",
        "      stat_list.append((base_tone, scale_label, scale_statistics[base_tone][scale_label]))\n",
        "  stat_list.sort(key=lambda e: e[2], reverse=True)\n",
        "  return (stat_list[0][0]+' '+stat_list[0][1], stat_list[0][2])\n",
        "\n",
        "def tone_to_freq(tone):\n",
        "  \"\"\"\n",
        "    returns the frequency of a tone. \n",
        "    formulas from\n",
        "      * https://en.wikipedia.org/wiki/MIDI_Tuning_Standard\n",
        "      * https://en.wikipedia.org/wiki/Cent_(music)\n",
        "  \"\"\"\n",
        "  return math.pow(2, ((float(tone)-69.0)/12.0)) * 440.0\n",
        "\n",
        "def freq_to_tone(freq):\n",
        "  \"\"\"\n",
        "    returns a dict d where\n",
        "    d['tone'] is the base tone in midi standard\n",
        "    d['cents'] is the cents to make the tone into the exact-ish frequency provided.\n",
        "               multiply this with 8192 to get the midi pitch level.\n",
        "    formulas from\n",
        "      * https://en.wikipedia.org/wiki/MIDI_Tuning_Standard\n",
        "      * https://en.wikipedia.org/wiki/Cent_(music)\n",
        "  \"\"\"\n",
        "  if freq == 0.0:\n",
        "    return None\n",
        "  float_tone = (69.0+12*math.log(float(freq)/440.0, 2))\n",
        "  int_tone = int(float_tone)\n",
        "  cents = int(1200*math.log(float(freq)/tone_to_freq(int_tone), 2))\n",
        "  return {'tone': int_tone, 'cents': cents}\n",
        "\n",
        "def cents_to_pitchwheel_units(cents):\n",
        "  return int(40.96*(float(cents)))\n",
        "\n",
        "def get_all_stats(midi_pattern):\n",
        "  stats = {}\n",
        "  if not midi_pattern:\n",
        "    print('Failed to read midi pattern.')\n",
        "    return None\n",
        "  tones = get_tones(midi_pattern)\n",
        "  if len(tones) == 0:\n",
        "    print('This is an empty song.')\n",
        "    return None\n",
        "  stats['num_tones'] = len(tones)\n",
        "  stats['tone_min'] = min(tones)\n",
        "  stats['freq_min'] = tone_to_freq(min(tones))\n",
        "  stats['tone_max'] = max(tones)\n",
        "  stats['freq_max'] = tone_to_freq(max(tones))\n",
        "  stats['tone_span'] = max(tones)-min(tones)\n",
        "  stats['freq_span'] = tone_to_freq(max(tones))-tone_to_freq(min(tones))\n",
        "  stats['tones_unique'] = len(set(tones))\n",
        "  rs = repetitions(tones)\n",
        "  for r in range(2,10):\n",
        "    if r in rs:\n",
        "      stats['repetitions_{}'.format(r)] = rs[r]\n",
        "    else:\n",
        "      stats['repetitions_{}'.format(r)] = 0\n",
        "  \n",
        "  ml = max_likelihood_scale(tones)\n",
        "  stats['scale'] = ml[0]\n",
        "  stats['scale_score'] = ml[1]\n",
        "  \n",
        "  beat_stats = detect_beat(midi_pattern)\n",
        "  minval = float(midi_pattern.resolution)\n",
        "  argmin = -1\n",
        "  for beat in beat_stats:\n",
        "    #print('Looking at beat: {}. Avg ticks off: {}.'.format(beat, beat_stats[beat]))\n",
        "    if beat_stats[beat] < minval:\n",
        "      minval = beat_stats[beat]\n",
        "      argmin = beat\n",
        "  stats['estimated_beat'] = argmin\n",
        "  stats['estimated_beat_avg_ticks_off'] = minval\n",
        "  (min_int, max_int) = get_intensities(midi_pattern)\n",
        "  stats['intensity_min'] = min_int\n",
        "  stats['intensity_max'] = max_int\n",
        "  stats['intensity_span'] = max_int-min_int\n",
        "\n",
        "  stats['polyphony_score'] = get_polyphony_score(midi_pattern)\n",
        "  stats['top_10_intervals'] = get_top_k_intervals(midi_pattern, 10)\n",
        "  stats['top_2_interval_difference'] = 0.0\n",
        "  if len(stats['top_10_intervals']) > 1:\n",
        "    stats['top_2_interval_difference'] = abs(stats['top_10_intervals'][1][0]-stats['top_10_intervals'][0][0])\n",
        "  stats['top_3_interval_difference'] = 0.0\n",
        "  if len(stats['top_10_intervals']) > 2:\n",
        "    stats['top_3_interval_difference'] = abs(stats['top_10_intervals'][2][0]-stats['top_10_intervals'][0][0])\n",
        "\n",
        "  return stats\n",
        "\n",
        "def get_gnuplot_line(midi_patterns, i, showheader=True):\n",
        "  stats = []\n",
        "  print('#getting stats...')\n",
        "  stats_time = time.time()\n",
        "  for p in midi_patterns:\n",
        "    stats.append(get_all_stats(p))\n",
        "  print('done. time: {}'.format(time.time()-stats_time))\n",
        "  #print(stats)\n",
        "  stats_keys_string = ['scale']\n",
        "  stats_keys = ['scale_score', 'tone_min', 'tone_max', 'tone_span', 'freq_min', 'freq_max', 'freq_span', 'tones_unique', 'repetitions_2', 'repetitions_3', 'repetitions_4', 'repetitions_5', 'repetitions_6', 'repetitions_7', 'repetitions_8', 'repetitions_9', 'estimated_beat', 'estimated_beat_avg_ticks_off', 'intensity_min', 'intensity_max', 'intensity_span', 'polyphony_score', 'top_2_interval_difference', 'top_3_interval_difference', 'num_tones']\n",
        "  gnuplotline = ''\n",
        "  if showheader:\n",
        "    gnuplotline = '# global-step {} {}\\n'.format(' '.join([s.replace(' ', '_') for s in stats_keys_string]), ' '.join(stats_keys))\n",
        "  gnuplotline += '{} {} {}\\n'.format(i, ' '.join(['{}'.format(stats[0][key].replace(' ', '_')) for key in stats_keys_string]), ' '.join(['{:.3f}'.format(sum([s[key] for s in stats])/float(len(stats))) for key in stats_keys]))\n",
        "  return gnuplotline\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "  if len(sys.argv) > 2 and sys.argv[1] == '--gnuplot':\n",
        "    #number = sys.argv[2]\n",
        "    patterns = []\n",
        "    for i in range(3,len(sys.argv)):\n",
        "      #print(i)\n",
        "      filename = sys.argv[i]\n",
        "      print('#File: {}'.format(filename))\n",
        "      #patterns.append(get_midi_pattern(filename))\n",
        "      print(get_gnuplot_line([get_midi_pattern(filename)], i, showheader=(i==0)))\n",
        "    \n",
        "  else:\n",
        "    for i in range(1,len(sys.argv)):\n",
        "      #filename = sys.argv[i]\n",
        "      filename = MIDI_file_to_analyze\n",
        "      print('File: {}'.format(filename))\n",
        "      midi_pattern = get_midi_pattern(filename)\n",
        "      stats = get_all_stats(midi_pattern)\n",
        "      if stats is None:\n",
        "        print('Could not extract stats.')\n",
        "      else:\n",
        "        print ('ML scale estimate: {}: {:.2f}'.format(stats['scale'], stats['scale_score']))\n",
        "        print ('Min tone: {}, {:.1f} Hz.'.format(tone_to_tone_name(stats['tone_min']), stats['freq_min']))\n",
        "        print ('Max tone: {}, {:.1f} Hz.'.format(tone_to_tone_name(stats['tone_max']), stats['freq_max']))\n",
        "        print ('Span: {} tones, {:.1f} Hz.'.format(stats['tone_span'], stats['freq_span']))\n",
        "        print ('Unique tones: {}'.format(stats['tones_unique']))\n",
        "        for r in range(2,10):\n",
        "          print('Repetitions of len {}: {}'.format(r, stats['repetitions_{}'.format(r)]))\n",
        "        print('Estimated beat: {}. Avg ticks off: {:.2f}.'.format(stats['estimated_beat'], stats['estimated_beat_avg_ticks_off']))\n",
        "        print('Intensity: min: {}, max: {}.'.format(stats['intensity_min'], stats['intensity_max']))\n",
        "        print('Polyphonous events: {:.2f}.'.format(stats['polyphony_score']))\n",
        "        print('Top intervals:')\n",
        "        for interval,score in stats['top_10_intervals']:\n",
        "          print('{}: {:.2f}.'.format(interval,score))\n",
        "        print('Top 2 interval difference: {}.'.format(stats['top_2_interval_difference']))\n",
        "        print('Top 3 interval difference: {}.'.format(stats['top_3_interval_difference']))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVCTFGaaOK43",
        "cellView": "form"
      },
      "source": [
        "#@title MIDI Stats 3 (Ground Truth)\n",
        "# https://github.com/mbereket/music-transcription\n",
        "\n",
        "# Comverts MIDI file pattern to representation of notes events in absolute time\n",
        "class NoteEvents:\n",
        "    def __init__(self, pattern, note_tracks=None, start_on_note=True):\n",
        "        self._event_list = []\n",
        "        self.note_time_list = []\n",
        "        pattern.make_ticks_abs()\n",
        "        self.pattern = pattern\n",
        "        self.ticks_per_beat = pattern.resolution\n",
        "        self.numNotes = 88\n",
        "        # offset between note index and MIDI note number\n",
        "        self.noteOffset = 9\n",
        "        # list of track names to include notes from\n",
        "        self.note_tracks = note_tracks\n",
        "        self.names = self._name_tracks()\n",
        "        self.start_on_note = start_on_note\n",
        "        self._parse_events()\n",
        "\n",
        "    def _name_tracks(self):\n",
        "        names = [None] * len(self.pattern)\n",
        "        for i in range(len(self.pattern)):\n",
        "            for event in self.pattern[i]:\n",
        "                if type(event) == midi.events.TrackNameEvent:\n",
        "                    names[i] = event.text\n",
        "                break\n",
        "        return names\n",
        "\n",
        "    def _parse_events(self):\n",
        "        for i in range(len(self.pattern)):\n",
        "            for event in self.pattern[i]:\n",
        "                if type(event) in (midi.events.NoteOnEvent, midi.events.NoteOffEvent):\n",
        "                    if self.note_tracks == None or self.names[i] in self.note_tracks:\n",
        "                        self._event_list.append(event)\n",
        "                elif type(event) == midi.events.SetTempoEvent:\n",
        "                    self._event_list.append(event)\n",
        "                elif type(event) == midi.events.EndOfTrackEvent and event.tick != 0:\n",
        "                    self._event_list.append(event)\n",
        "        self._event_list = sorted(self._event_list, key=lambda x: x.tick)\n",
        "        self._event_list_timed()\n",
        "\n",
        "\n",
        "    def _event_list_timed(self):\n",
        "        assert(type(self._event_list[0]) == midi.events.SetTempoEvent)\n",
        "        microseconds_per_beat = self._event_list[0].get_mpqn()\n",
        "        prev_time = 0\n",
        "        prev_tick = 0\n",
        "        microseconds_per_tick = float(microseconds_per_beat) / self.ticks_per_beat\n",
        "        for event in self._event_list:\n",
        "            tick_diff = event.tick - prev_tick\n",
        "            curr_time = prev_time + (tick_diff * microseconds_per_tick)\n",
        "            if type(event) != midi.events.SetTempoEvent:\n",
        "                self.note_time_list.append((event, curr_time))\n",
        "                prev_time = curr_time\n",
        "                prev_tick = event.tick\n",
        "            else:\n",
        "                prev_time = curr_time\n",
        "                prev_tick = event.tick\n",
        "                microseconds_per_beat = event.get_mpqn()\n",
        "                microseconds_per_tick = float(microseconds_per_beat) / self.ticks_per_beat\n",
        "        start_time = self.note_time_list[0][1]\n",
        "\n",
        "        if self.start_on_note:\n",
        "            for i, tup in enumerate(self.note_time_list):\n",
        "                self.note_time_list[i] = (tup[0],tup[1]-start_time)\n",
        "        self._last_event_time = self.note_time_list[-1][1]\n",
        "\n",
        "    def _note_off(self, note_event):\n",
        "        return ((type(note_event) == midi.events.NoteOnEvent) and (note_event.get_velocity() == 0)) \\\n",
        "                    or type(note_event) == midi.events.NoteOffEvent\n",
        "\n",
        "    # returns index of first slice at or after given time\n",
        "    # time in microseconds\n",
        "    def time_to_slice(self, t, slices_per_second):\n",
        "        microseconds_per_slice = 1e6 / slices_per_second\n",
        "        return np.ceil(float(t) / microseconds_per_slice).astype(int)\n",
        "\n",
        "    # duration in seconds\n",
        "    def get_ground_truth(self, slices_per_second, duration=None):\n",
        "        microseconds_per_slice = 1e6 / slices_per_second\n",
        "        number_slices = np.ceil(self._last_event_time / microseconds_per_slice).astype(int)\n",
        "        ground_truth = np.zeros(self.numNotes * number_slices).reshape(self.numNotes, number_slices)\n",
        "        template = np.zeros(self.numNotes).reshape(self.numNotes,1)\n",
        "        prev_time = 0\n",
        "        for note, curr_time in self.note_time_list:\n",
        "            if prev_time != curr_time:\n",
        "                prev_time_slice = self.time_to_slice(prev_time, slices_per_second)\n",
        "                curr_time_slice = self.time_to_slice(curr_time, slices_per_second)\n",
        "                #make all slices in [prev_time, curr_time) equal to current template\n",
        "                ground_truth[:,prev_time_slice:curr_time_slice] = template.repeat(curr_time_slice - prev_time_slice, axis=1)\n",
        "            if type(note) == midi.events.EndOfTrackEvent:\n",
        "                break\n",
        "            pitch_index = note.get_pitch() - self.noteOffset\n",
        "            if pitch_index >= 0 and pitch_index < self.numNotes:\n",
        "                if self._note_off(note):\n",
        "                    template[pitch_index] = 0\n",
        "                else:\n",
        "                    template[pitch_index] = 1\n",
        "            prev_time = curr_time\n",
        "        if duration != None:\n",
        "            ground_truth = ground_truth[:,:self.time_to_slice(1e6 * duration, slices_per_second)]\n",
        "        return ground_truth\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    pattern = midi.read_midifile(MIDI_file_to_analyze)\n",
        "    events = NoteEvents(pattern)\n",
        "    truth = events.get_ground_truth(31.25, 15)\n",
        "    plt.matshow(truth)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPaJ_5WRXc_F",
        "cellView": "form"
      },
      "source": [
        "#@title MIDI Stats 4\n",
        "# https://github.com/Astner/exjobb/blob/1abc750a7a4d9af52e273ef24c2c32d0e431e1a6/concepts-master/experimental/higherorder/formats/midi/miditocontext/midiutils.py\n",
        "# \n",
        "\n",
        "# Copyright 2015 Daniel Gillblad (dgi@sics.se).\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\")\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "# http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "# Selecte active channels\n",
        "# Here, all channels except 10 are used, as this MIDI channel is used for percussion only\n",
        "# in General MIDI files (note that we index channels from 0, not 1)\n",
        "activeChannels = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15)\n",
        "\n",
        "# Time during which events are considered simultaneous\n",
        "simTimeLimit = 50\n",
        "\n",
        "# Fraction of time notes need to be overlapping to be considered played together\n",
        "overlapFracLimit = 0.95\n",
        "\n",
        "# Print info on specified MIDI file\n",
        "def printMidiFileInfo(midifile):\n",
        "\tmid = MidiFile(midifile)\n",
        "\tprint(\"File:\", os.path.basename(midifile),\n",
        "\t      \"Type:\", mid.type,\n",
        "\t      \"Length: \",\n",
        "\t      end = \"\")\n",
        "\tif mid.type < 2:\n",
        "\t\tprint(mid.length)\n",
        "\telse:\n",
        "\t\tprint(\"N/A\")\n",
        "\n",
        "# Print messages in MIDI file\n",
        "def printMidiMessages(midifile):\n",
        "\tmid = MidiFile(midifile)\n",
        "\tfor i, track in enumerate(mid.tracks):\n",
        "\t\tprint('Track {}: {}'.format(i, track.name))\n",
        "\t\tfor message in track:\n",
        "\t\t\tprint(message)\n",
        "\n",
        "# Simple class for representing current note state,\n",
        "# given a series of messages given in order to the update method.\n",
        "class NoteState:\n",
        "\tnstate = [-1] * 128\n",
        "\n",
        "\tdef printState(self):\n",
        "\t\tprint('|', end = '')\n",
        "\t\tfor i in self.nstate[22:116]:\n",
        "\t\t\tif i >= 0:\n",
        "\t\t\t\tprint('*', end = '')\n",
        "\t\t\telse:\n",
        "\t\t\t\tprint('-', end = '')\n",
        "\t\tprint('|')\n",
        "\n",
        "\tdef update(self, message, time = 0):\n",
        "\t\tif message.type == 'all_notes_off':\n",
        "\t\t\tself.nstate = [-1] * 128\n",
        "\t\telif message.type == 'note_off' or (message.type == 'note_on' and message.velocity <= 0):\n",
        "\t\t\trmsg = [(self.nstate[message.note], time, message.note)]\n",
        "\t\t\tself.nstate[message.note] = -1\n",
        "\t\t\treturn rmsg\n",
        "\t\telif message.type == 'note_on':\n",
        "\t\t\tself.nstate[message.note] = time\n",
        "\t\t\treturn []\n",
        "\t\treturn []\n",
        "\n",
        "# Determines if a message is a \"note\" message: note on, note off, or all notes off\n",
        "def isNoteMessage(msg):\n",
        "\tif msg.type == 'note_on' or msg.type == 'note_off' or msg.type == 'all_notes_off':\n",
        "\t\treturn True\n",
        "\telse:\n",
        "\t\treturn False\n",
        "\n",
        "# Determines if a message is a \"note\" message on a specific channel\n",
        "def isNoteMessageOnChannel(msg, ch):\n",
        "\tif isNoteMessage(msg) and msg.channel == ch:\n",
        "\t\treturn True\n",
        "\telse:\n",
        "\t\treturn False\n",
        "\n",
        "# Convert a MIDI file to a list of note events, each note given by\n",
        "# (start-time, end-time, note number). Returns a nested list with\n",
        "# one list per channel per track.\n",
        "def fileToNoteList(midifile):\n",
        "\tmid = MidiFile(midifile)\n",
        "\tallnotes = []\n",
        "\tfor i, track in enumerate(mid.tracks):\n",
        "\t\ttracknotes = []\n",
        "\t\tfor channel in activeChannels:\n",
        "\t\t\tchannelnotes = []\n",
        "\t\t\tstate = NoteState()\n",
        "\t\t\tcTime = 0\n",
        "\t\t\tfor message in track:\n",
        "\t\t\t\tcTime += message.time\n",
        "\t\t\t\tif isNoteMessageOnChannel(message, channel):\n",
        "\t\t\t\t\tchannelnotes += state.update(message, cTime)\n",
        "\t\t\tif len(channelnotes) >= 1:\n",
        "\t\t\t\ttracknotes += [sorted(channelnotes, key=itemgetter(0,1))]\n",
        "\t\tif len(tracknotes) >= 1:\n",
        "\t\t\tallnotes += [tracknotes]\n",
        "\treturn allnotes\n",
        "\n",
        "# Convert a note list to a list of notes played together.\n",
        "def playedTogether(notelist):\n",
        "\ttogether = []\n",
        "\tfor i, note in enumerate(notelist):\n",
        "\t\t# Find overlaps\n",
        "\t\tfor fnote in notelist[i + 1:]:\n",
        "\t\t\tif fnote[0] > note[1]:\n",
        "\t\t\t\tbreak\n",
        "\t\t\toverlap_a = (note[1] - fnote[0]) / (note[1] - note[0])\n",
        "\t\t\toverlap_b = (fnote[1] - note[1]) / (fnote[1] - fnote[0])\n",
        "\t\t\tif overlap_a >= overlapFracLimit or overlap_b >= overlapFracLimit:\n",
        "\t\t\t\ttogether += [[note[2], fnote[2]]]\n",
        "\treturn together\n",
        "\n",
        "# Find all notes played together in midifile, separated by track and channel\n",
        "def allNotesPlayedTogether(midifile):\n",
        "\tnotelists = fileToNoteList(midifile)\n",
        "\talltogether = []\n",
        "\tfor t in notelists:\n",
        "\t\tfor c in t:\n",
        "\t\t\talltogether += playedTogether(c)\n",
        "\treturn alltogether\n",
        "\n",
        "# Print a graphic representation of all note messages in a MIDI file\n",
        "# on a (reasonable) easy to read format.\n",
        "def printNoteMessages(midifile):\n",
        "\tmid = MidiFile(midifile)\n",
        "\tfor i, track in enumerate(mid.tracks):\n",
        "\t\tprint('Track {}: {}'.format(i, track.name))\n",
        "\t\tfor channel in activeChannels:\n",
        "\t\t\tprint('Channel:', channel)\n",
        "\t\t\tstate = NoteState()\n",
        "\t\t\tcTime = 0\n",
        "\t\t\tsimTime = 0\n",
        "\t\t\tfor message in track:\n",
        "\t\t\t\tcTime += message.time\n",
        "\t\t\t\tif isNoteMessageOnChannel(message, channel):\n",
        "\t\t\t\t\t# If message is outside what would be considered simultaneous,\n",
        "\t\t\t\t\t# emit last state and reset simultaneous time counter\n",
        "\t\t\t\t\tif (simTime + message.time) >= simTimeLimit:\n",
        "\t\t\t\t\t\tprint(cTime, end = '')\n",
        "\t\t\t\t\t\tstate.printState()\n",
        "\t\t\t\t\t\tsimTime = 0\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tsimTime += message.time\n",
        "\t\t\t\t\tstate.update(message, cTime)\n",
        "\n",
        "# Print a graphic representation of all note messages in a MIDI file\n",
        "# on a (reasonable) easy to read format, grouping near simultaneous note events\n",
        "# for readability.\n",
        "def printGroupedNoteOnMessages(midifile):\n",
        "\tmid = MidiFile(midifile)\n",
        "\tfor i, track in enumerate(mid.tracks):\n",
        "\t\tprint('Track {}: {}'.format(i, track.name))\n",
        "\t\tfor channel in activeChannels:\n",
        "\t\t\tprint('Channel:', channel)\n",
        "\t\t\tcTime = 0\n",
        "\t\t\tgTime = 0\n",
        "\t\t\tnSet = set()\n",
        "\t\t\tfor message in track:\n",
        "\t\t\t\tcTime += message.time\n",
        "\t\t\t\tif message.type == 'note_on' and message.velocity > 0 and message.channel == channel:\n",
        "\t\t\t\t\tif (cTime - gTime) >= simTimeLimit:\n",
        "\t\t\t\t\t\tprint(cTime, nSet)\n",
        "\t\t\t\t\t\tgTime = cTime\n",
        "\t\t\t\t\t\tnSet.clear()\n",
        "\t\t\t\t\t\tnSet.add(message.note)\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tnSet.add(message.note)\n",
        "\n",
        "# Collect a set of statistics for a specified MIDI file object.\n",
        "def collectMidiNoteStatistics(midifileobj, channel_activity, played_notes, note_offs,\n",
        "                              running_status, all_notes_off):\n",
        "\tfor i, track in enumerate(midifileobj.tracks):\n",
        "\t\tfor channel in activeChannels:\n",
        "\t\t\tfor message in track:\n",
        "\t\t\t\tif(isNoteMessage(message)):\n",
        "\t\t\t\t\tchannel_activity[message.channel] += 1\n",
        "\t\t\t\t\tif message.type == 'note_on' and message.velocity > 0:\n",
        "\t\t\t\t\t\tplayed_notes[message.note] += 1\n",
        "\t\t\t\t\tif message.type == 'note_off':\n",
        "\t\t\t\t\t\tnote_offs[message.channel] += 1\n",
        "\t\t\t\t\tif message.type == 'note_on' and message.velocity <= 0:\n",
        "\t\t\t\t\t\trunning_status[message.channel] += 1\n",
        "\t\t\t\t\tif message.type == 'all_notes_off':\n",
        "\t\t\t\t\t\tall_notes_off[message.channel] += 1\n",
        "\n",
        "# Print MIDI file statistics compiled for all MIDI files found in the specified directory\n",
        "# and all sub-directories recursively.\n",
        "def printMidiFileStatistics(root_dir):\n",
        "    nr_files = 0\n",
        "    nr_file_types = [0] * 3\n",
        "    nr_length_files = 0\n",
        "    total_length = 0\n",
        "    channel_activity = [0] * 16\n",
        "    played_notes = [0] * 127\n",
        "    note_offs = [0] * 16 # Per channel\n",
        "    running_status = [0] * 16 # Per channel\n",
        "    all_notes_off = [0] * 16 # Per channel\n",
        "\n",
        "    mid = MidiFile(MIDI_file_to_analyze)\n",
        "    nr_files += 1\n",
        "    nr_file_types[mid.type] += 1\n",
        "    if mid.type < 2:\n",
        "      nr_length_files += 1\n",
        "      total_length += mid.length\n",
        "    collectMidiNoteStatistics(mid, channel_activity, played_notes, note_offs,\n",
        "                              running_status, all_notes_off)\n",
        "\n",
        "    print('--------------------------------------------------------------------------')\n",
        "    print('Number of .mid files:', nr_files, '      Type 0:', nr_file_types[0],\n",
        "          ' Type 1:', nr_file_types[1], ' Type 2:', nr_file_types[2])\n",
        "    print('Average length:       {:.1f}'.format(total_length / nr_length_files))\n",
        "    print('--------------------------------------------------------------------------')\n",
        "    print('Note on messages:    ', sum(played_notes))\n",
        "    print('Note off messages:   ', sum(note_offs))\n",
        "    print('Running status off:  ', sum(running_status))\n",
        "    print('All notes off:       ', sum(all_notes_off))\n",
        "    print('--------------------------------------------------------------------------')\n",
        "    print('Channel activity distribution:')\n",
        "    total_activity = sum(channel_activity)\n",
        "    for i, act in enumerate(channel_activity):\n",
        "      if act > 0:\n",
        "        print('{:2d}: {:.1%} '.format(i + 1, act / total_activity))\n",
        "    print('--------------------------------------------------------------------------')\n",
        "    print('Note distribution:')\n",
        "    total_notes = sum(played_notes)\n",
        "    for i, nt in enumerate(played_notes):\n",
        "      if nt > 0:\n",
        "        print('{:2d}: {:.2%} '.format(i, nt / total_notes))\n",
        "    print('--------------------------------------------------------------------------')\n",
        "\n",
        "\n",
        "# Visit files recursively from a root directory.\n",
        "def visitFilesRecursively(root_dir, extension, apply_func, verbose = True):\n",
        "\tbase_dir = os.path.abspath(root_dir)\n",
        "\tfor root, subdirs, files in os.walk(base_dir):\n",
        "\t\tif verbose:\n",
        "\t\t\tprint('# Directory: ' + root)\n",
        "\t\tfor filename in files:\n",
        "\t\t\tif os.path.splitext(filename)[1] == extension:\n",
        "\t\t\t\tif verbose:\n",
        "\t\t\t\t\tprint('  - %s ' % (filename))\n",
        "\t\t\t\tfile_path = os.path.join(root, filename)\n",
        "\t\t\t\tres = apply_func(file_path)\n",
        "    \n",
        "printMidiFileStatistics('/content/')    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "E4IM7Un3Lft7"
      },
      "source": [
        "#@title Time varying key of a MIDI file\n",
        "# Identifies the time varying key of a MIDI file\n",
        "# Hilary Mogul\n",
        "# hilary.mogul@gmail.com\n",
        "# May 2014\n",
        "# Version 0.0.1\n",
        "from pretty_midi import PrettyMIDI\n",
        "import numpy as np\n",
        "import midi\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def make_chroma_vector(chroma_slice):\n",
        "  \"\"\"Returns chroma vector of sums from starting time to ending time\"\"\"\n",
        "  chroma_vector = np.zeros((12,1))\n",
        "  chroma_vector[0] = np.sum(chroma_slice[11,])\n",
        "  for i in range(1,12):\n",
        "    chroma_vector[i] = np.sum(chroma_slice[11-i])\n",
        "  return chroma_vector\n",
        "\n",
        "def get_approx_key(chroma_vector, keys):\n",
        "  \"\"\"Returns index of approximated key, and the score that this approximated key got\"\"\"\n",
        "  chroma_vector = chroma_vector[:]\n",
        "  scores = []\n",
        "  end = keys.shape[0] -1\n",
        "  for i in range(0,end):\n",
        "    key_vector = keys[i,:]\n",
        "    score = np.dot(key_vector,chroma_vector)\n",
        "    scores.append(score)\n",
        "  key_index = scores.index(max(scores))\n",
        "  arr = np.array([[key_index, max(scores)]])\n",
        "  return arr\n",
        "\n",
        "def get_key_score(chroma_vector, keys, key_index):\n",
        "  \"\"\"Returns the score of an approximated key, given the index of the key weights to try out\"\"\"\n",
        "  chroma_vector = np.rot90(chroma_vector,3)\n",
        "  chroma_vector = chroma_vector[0,:]\n",
        "  key_vector = keys[key_index,:]\n",
        "  score = np.dot(key_vector,chroma_vector)\n",
        "  return score\n",
        "\n",
        "\n",
        "def load_keys():\n",
        "  \"\"\" Returns arrays of the weighted keys, and the corresponding names of them \"\"\"\n",
        "  #Building of weighted vectors\n",
        "  if not os.path.exists(\"key_base_info.npz\"):\n",
        "    print(\"Building default array- major keys only\")\n",
        "    key_weight = np.array([[ 3, -1,  1, -1,  2,  1, -1,  2, -1,  1, -1,  2]])\n",
        "    key_weight = np.vstack((key_weight,np.array([[2,  3, -1,  1, -1,  2,  1, -1,  2, -1,  1, -1]])))\n",
        "    key_weight = np.vstack((key_weight,np.array([[-1,  2,  3, -1,  1, -1,  2,  1, -1,  2, -1,  1]])))\n",
        "    key_weight = np.vstack((key_weight,np.array([[1, -1,  2,  3, -1,  1, -1,  2,  1, -1,  2, -1]])))\n",
        "    key_weight = np.vstack((key_weight,np.array([[-1,  1, -1,  2,  3, -1,  1, -1,  2,  1, -1,  2]])))\n",
        "    key_weight = np.vstack((key_weight,np.array([[2, -1,  1, -1,  2,  3, -1,  1, -1,  2,  1, -1]])))\n",
        "    key_weight = np.vstack((key_weight,np.array([[-1,  2, -1,  1, -1,  2,  3, -1,  1, -1,  2,  1]])))\n",
        "    key_weight = np.vstack((key_weight,np.array([[1, -1,  2, -1,  1, -1,  2,  3, -1,  1, -1,  2]])))\n",
        "    key_weight = np.vstack((key_weight,np.array([[2,  1, -1,  2, -1,  1, -1,  2,  3, -1,  1, -1]])))\n",
        "    key_weight = np.vstack((key_weight,np.array([[-1,  2,  1, -1,  2, -1,  1, -1,  2,  3, -1,  1]])))\n",
        "    key_weight = np.vstack((key_weight,np.array([[1, -1,  2,  1, -1,  2, -1,  1, -1,  2,  3, -1]])))\n",
        "    key_weight = np.vstack((key_weight,np.array([[-1,  1, -1,  2,  1, -1,  2, -1,  1, -1,  2,  3]])))\n",
        "    names = np.array([['C-Maj', 'C#-Maj', 'D-Maj', 'D#-Maj', 'E-Maj', 'F-Maj','F#-Maj','G-Maj','G#-Maj', 'A-Maj', 'A#-Maj','B-Maj']])\n",
        "    np.savez(\"key_base_info\", key_weight, names)\n",
        "  npzfile = np.load(\"key_base_info.npz\")\n",
        "  key_weight = npzfile['arr_0']\n",
        "  names = npzfile['arr_1']\n",
        "  #vector of key names (This version will use only major keys)\n",
        "\n",
        "  return key_weight, names\n",
        "\n",
        "\n",
        "#Main function of program:\n",
        "def identify_key(midi_filename, command_line_print = True, save_results = True, measure_value = 1):\n",
        "  \"\"\" Runs key identification algorithm\n",
        "  :parameters:\n",
        "    - midi_filename : String of name of existing midi file to process.\n",
        "    - command_line_print : Boolean to allow for printing results to command line.\n",
        "    - save_results : Boolean to allow saving the approximated key and the names of those keys to a .npz file matching the midi files name\n",
        "    - measure_value : int > 0 that sets how many beats the program will process per approximation.\n",
        "    \"\"\"\n",
        "\n",
        "  song = PrettyMIDI((midi_filename))\n",
        "\n",
        "  #get beat locations for slices\n",
        "  beats = song.get_beats() #output is an np.ndarray\n",
        "  times = beats.flatten()\n",
        "  sectionBeats = True\n",
        "  #create slices of chroma data to process including summing them up\n",
        "  #output: every \"measure\" of beats\n",
        "\n",
        "  if measure_value< 1 or measure_value >times.size or measure_value == None:\n",
        "    sectionBeats = False\n",
        "    print (\"WARNING: measure_value selected less than 1 or greater than beat size.  Will do one approximation for the whole song.\")\n",
        "\n",
        "\n",
        "\n",
        "  key_weight, names = load_keys()\n",
        "  #get Chroma features\n",
        "  chroma = song.get_chroma()\n",
        "  #normalize chroma features\n",
        "  chroma /= (chroma.max( axis = 0 ) + (chroma.max( axis = 0 ) == 0))\n",
        "\n",
        "  # first case\n",
        "  if sectionBeats:\n",
        "    chroma_slice = chroma[:,0:round(times[0])*100]\n",
        "  else:\n",
        "    chroma_slice = chroma\n",
        "  # Sum rows to find intensity of each note.\n",
        "  vec = np.sum(chroma_slice, axis=1)\n",
        "  keys_approx = get_approx_key(vec, key_weight)\n",
        "\n",
        "  #for each slice, get approximated key and score into 2 column array (key, score)\n",
        "  #possiblymay need to use indices of key names instead of actual keys\n",
        "  #chroma time indices have a resolution of 10 ms\n",
        "\n",
        "  times_used = np.array([[times[0]]])\n",
        "\n",
        "  if sectionBeats:\n",
        "    for t in range(1, times.size-1,measure_value):\n",
        "    #make chroma slice based on time\n",
        "      if times.size -t < measure_value:\n",
        "        chroma_slice = chroma[:,round(times[t]*100):round(times[t+1]*100)]\n",
        "      # print chroma_slice\n",
        "      # vec = make_chroma_vector(chroma_slice)\n",
        "        vec = np.sum(chroma_slice, axis=1)\n",
        "      # vec = vec[::-1]\n",
        "      else:\n",
        "        chroma_slice = chroma[:,round(times[t]*100):round(times[t+1]*100)]\n",
        "      # print chroma_slice\n",
        "      # vec = make_chroma_vector(chroma_slice)\n",
        "        vec = np.sum(chroma_slice, axis=1)\n",
        "      # vec = vec[::-1]\n",
        "      apr = get_approx_key(vec, key_weight)\n",
        "      #if the score isn't 0 (which happens in silence), add the approximated key to the list\n",
        "      if not apr[0,1] == 0:\n",
        "        keys_approx = np.vstack((keys_approx, apr))\n",
        "        times_used = np.vstack((times_used, np.array([[times[t]]])))\n",
        "\n",
        "\n",
        "  # DUMMIED OUT CODE FOR FUTURE IMPLEMENTATION\n",
        "  # final_keys = np.array([ [ keys_approx[0,0],times[0,0] ] ]) #mark first\n",
        "  # print final_keys\n",
        "  #\n",
        "  # #iterate through rows of array- if there is a change, get % difference in scores for each key and use threshold to figure\n",
        "  # #if it is a key change.  mark key change in final 2 column array of (key, time start)\n",
        "  # threshold = .15 #experimental value\n",
        "  #\n",
        "  # if times.size > 1:\n",
        "  #   print \"going thru removal loop\"\n",
        "  #   for t in range (1, keys_approx.shape[0]):\n",
        "  #     current = keys_approx[t,0]\n",
        "  #     prev = keys_approx[t-1,0]\n",
        "  #     if not current == prev: #if not equal to previous, check % difference of scores\n",
        "  #       print \"In key change check\"\n",
        "  #       score1 = keys_approx[t,1] #score of key of this time slice\n",
        "  #       # print score1\n",
        "  #       vec = make_chroma_vector(chroma, round(times[0,t])*100,round(times[0,t+1])*100 )\n",
        "  #       # print vec\n",
        "  #       score2 = get_key_score(vec, key_weight, prev) #score it would have gotten with last input key\n",
        "  #       # print score2\n",
        "  #       diff = abs(score1-score2)/(score1+score2)\n",
        "  #       print diff\n",
        "  #       if diff > threshold:\n",
        "  #         arr = np.array([[keys_approx[t,0], times[t,0] ]])\n",
        "  #         # print arr\n",
        "  #         print \"Key change at index: \", times[t,0]\n",
        "  #         final_keys = np.vstack((final_keys, arr))\n",
        "  #       else:\n",
        "  #         print \"difference not large enough to constitute key change \"\n",
        "\n",
        "  #keys_approx = final_keys\n",
        "  e = keys_approx.shape[0]\n",
        "  if command_line_print:\n",
        "    for i in range(0, e):\n",
        "      key_int = int(keys_approx[i,0])\n",
        "      print(\"In key: \",names[0,key_int],\"at time: \", times_used[i,0])\n",
        "  if save_results:\n",
        "    filename = os.path.basename(midi_filename)\n",
        "    filename_raw = os.path.splitext(filename)[0]\n",
        "    # if not os.path.exists(directory):\n",
        "    dirname = \"Results_of_key_approximation\"\n",
        "    if not os.path.exists(dirname):\n",
        "      os.makedirs(dirname)\n",
        "    np.savez(dirname+\"/\"+filename_raw+\"_key_approx-vars\", keys_approx = keys_approx, names = names)\n",
        "    file_results = open(dirname+\"/\"+filename_raw+\"_key_approx-text_form.txt\",'w')\n",
        "    file_results.write(filename_raw+\"\\n\")\n",
        "    for i in range(0, e):\n",
        "      key_int = int(keys_approx[i,0])\n",
        "      file_results.write(\"In key: \"+names[0,key_int]+\" at time: \"+ str(times_used[i,0])+\"\\n\")\n",
        "    file_results.close()\n",
        "  return keys_approx, names\n",
        "\n",
        "x = identify_key(MIDI_file_to_analyze)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "n7CM_Ij8M_Np"
      },
      "source": [
        "#@title Detailed chords analysis\n",
        "%cd /content/\n",
        "# https://github.com/realbchan/MidiAnalysis\n",
        "\n",
        "import bisect\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class Utils:\n",
        "\t# initialize, build mapping from a note number to a note letter\n",
        "\tdef __init__(self):\n",
        "\t\tself.number_to_letter_mappings = dict()\n",
        "\t\tself.pattern = ['A', 'A#/Bb', 'B', 'C', 'C#/Db', 'D', 'D#/Eb', 'E', 'F', 'F#/Gb', 'G', 'G#/Ab']\n",
        "\t\tself.build_number_letter_mapping()\n",
        "\n",
        "\t# this method maps a number to a note letter and it's octave\n",
        "\t# notes on my keyboard is from note=21 to note=108 == 88 keys\n",
        "\t# I dont think the piano can represent anything out of this range\n",
        "\tdef build_number_letter_mapping(self):\n",
        "\t\toctave = 0\n",
        "\t\tfor num_note in range(21, 109):\n",
        "\t\t\tletter = self.pattern[(num_note - 21) % len(self.pattern)]\n",
        "\t\t\tif letter == 'C':\n",
        "\t\t\t\toctave += 1\n",
        "\t\t\tnote = (self.pattern[(num_note - 21) % len(self.pattern)], octave)\n",
        "\n",
        "\t\t\tself.number_to_letter_mappings[num_note] = note\n",
        "\n",
        "\t# get method, retrieve note letter from note number\n",
        "\tdef note_number_to_letter(self, num_note):\n",
        "\t\treturn self.number_to_letter_mappings[num_note]\n",
        "\n",
        "# each note or chord is considered a \"Tone\"\n",
        "# This is the parent class for Note and Chord\n",
        "class Tone:\n",
        "\tdef __init__(self):\n",
        "\t\t# this threshold limit determines how \"close\"\n",
        "\t\t# a note is to another note in seconds, this can be tuned\n",
        "\t\tself.threshold_limit = .25\n",
        "\n",
        "\tdef is_note(self):\n",
        "\t\treturn False\n",
        "\tdef is_chord(self):\n",
        "\t\treturn False\n",
        "\t# must be implemented in Note and Chord\n",
        "\tdef is_close(self, other_note):\n",
        "\t\traise NotImplementedError(\"To be implemented\")\n",
        "\n",
        "# I define a Note to be a single musical note played\n",
        "# If there are 1 or 2 notes \"close\" by, it is considered a Chord\n",
        "class Note(Tone):\n",
        "\t# takes in parameters from message, calculates duration\n",
        "\tdef __init__(self, absoluteStart, absoluteStop, notePlayed, velocityStart, velocityStop):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.absoluteStart = absoluteStart\n",
        "\t\tself.absoluteStop = absoluteStop\n",
        "\t\tself.duration = self.absoluteStop - self.absoluteStart\n",
        "\t\tself.notePlayed = notePlayed\n",
        "\t\tself.velocityStart = velocityStart\n",
        "\t\tself.velocityStop = velocityStop\n",
        "\n",
        "\t# def __key(self):\n",
        "\t# \treturn (self.notePlayed[0], self.notePlayed[1])\n",
        "\n",
        "\t# def __hash__(self):\n",
        "\t# \treturn hash(self.__key())\n",
        "\n",
        "\tdef __lt__(self, other_note):\n",
        "\t\tnote_letter, note_octave = self.notePlayed[0], self.notePlayed[1]\n",
        "\t\tother_note_letter, other_note_octave = other_note.notePlayed[0], other_note.notePlayed[1]\n",
        "\t\tif note_octave < other_note_octave:\n",
        "\t\t\treturn True\n",
        "\t\telif note_octave == other_note_octave:\n",
        "\t\t\treturn other_note_letter < note_letter\n",
        "\t\telse:\n",
        "\t\t\treturn False\n",
        "\n",
        "\tdef __str__(self):\n",
        "\t\treturn str(self.notePlayed)\n",
        "\n",
        "\tdef __repr__(self):\n",
        "\t\treturn self.__str__()\n",
        "\n",
        "\tdef is_note(self):\n",
        "\t\treturn True\n",
        "\t# uses self.threshold to determine if a note is close\n",
        "\tdef is_close(self, other_note):\n",
        "\t\tstart_difference = abs(self.absoluteStart - other_note.absoluteStart)\n",
        "\t\tstop_difference = abs(self.absoluteStop - other_note.absoluteStop)\n",
        "\n",
        "\t\tif start_difference <= self.threshold_limit and stop_difference <= self.threshold_limit:\n",
        "\t\t\treturn True\n",
        "\t\treturn False\n",
        "\n",
        "# a chord is considered 1 or 2 notes that are close by\n",
        "class Chord(Tone):\n",
        "\t# we need to keep track of the average parameters of a chord\n",
        "\tdef __init__(self):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.notes_in_chord = tuple()\n",
        "\t\tself.num_chords = 0\n",
        "\t\tself.average_duration = 0\n",
        "\t\tself.average_start_time = 0\n",
        "\t\tself.average_stop_time = 0\n",
        "\n",
        "\tdef __str__(self):\n",
        "\t\treturn str(self.notes_in_chord)\n",
        "\n",
        "\t# def __key(self):\n",
        "\t# \treturn tuple(note.__hash__() for note in self.notes_in_chord)\n",
        "\n",
        "\t# def __hash__(self):\n",
        "\t# \treturn hash(self.__key())\n",
        "\n",
        "\n",
        "\tdef is_chord(self):\n",
        "\t\treturn True\n",
        "\n",
        "\t# on adding a note, recalculate averages\n",
        "\tdef add_note(self, note):\n",
        "\t\tself.average_duration = self.get_new_average(self.average_duration, note.duration)\n",
        "\t\tself.average_start_time = self.get_new_average(self.average_start_time, note.absoluteStart)\n",
        "\t\tself.average_stop_time = self.get_new_average(self.average_stop_time, note.absoluteStop)\n",
        "\n",
        "\t\tself.num_chords += 1\n",
        "\n",
        "\t\tnote_letter, note_octave = note.notePlayed\n",
        "\n",
        "\t\tlist_notes_in_chord = list(self.notes_in_chord)\n",
        "\t\tif len(self.notes_in_chord) > 0:\n",
        "\t\t\tbisect.insort_left(list_notes_in_chord, note)\n",
        "\t\telse:\n",
        "\t\t\tlist_notes_in_chord.append(note)\n",
        "\t\tself.notes_in_chord = tuple(list_notes_in_chord)\n",
        "\t\t# print(self.notes_in_chord)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t# calculate new arbitrary average\n",
        "\tdef get_new_average(self, previous_cumulation, next_number):\n",
        "\t\tprevious_sum = previous_cumulation * self.num_chords\n",
        "\t\tcurrent_sum = previous_sum + next_number\n",
        "\t\treturn current_sum / (self.num_chords + 1)\n",
        "\n",
        "\t# similar to is_close for Note\n",
        "\tdef is_close(self, other_note):\n",
        "\t\tstart_difference = abs(self.average_start_time - other_note.absoluteStart)\n",
        "\t\tstop_difference = abs(self.average_stop_time - other_note.absoluteStop)\n",
        "\t\t\n",
        "\n",
        "\t\tif start_difference <= self.threshold_limit and stop_difference <= self.threshold_limit:\n",
        "\t\t\treturn True\n",
        "\t\treturn False\n",
        "\n",
        "# a Song is a list of Tones\n",
        "# it represents a midi track as a whole\n",
        "class Song:\n",
        "\tdef __init__(self):\n",
        "\t\tself.tones = list()\n",
        "\n",
        "\tdef __str__(self):\n",
        "\n",
        "\t\treturn ''.join(str(tone) for tone in self.tones)\n",
        "\n",
        "\t# sorts tones by start\n",
        "\tdef sort_by_start_of_tone(self):\n",
        "\t\t# sorting comparator, probably could refactor\n",
        "\t\tdef get_start(tone):\n",
        "\t\t\tif tone.is_note():\n",
        "\t\t\t\treturn tone.absoluteStart\n",
        "\t\t\telse:\n",
        "\t\t\t\treturn tone.average_start_time\n",
        "\n",
        "\t\tself.tones.sort(key=get_start)\n",
        "\t# add note to song, will detect if needs to make a chord\n",
        "\tdef add_note(self, note):\n",
        "\t\t\n",
        "\t\tif len(self.tones) == 0:\n",
        "\t\t\tself.tones.append(note)\n",
        "\n",
        "\t\telse:\n",
        "\t\t\tfor previous_tone in self.tones[::-1]:\n",
        "\t\t\t\t# retrieve previous tone's end, chord or note\n",
        "\t\t\t\tprevious_tone_end = None\n",
        "\t\t\t\tif previous_tone.is_chord():\n",
        "\t\t\t\t\tprevious_tone_end = previous_tone.average_stop_time\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tprevious_tone_end = previous_tone.absoluteStop\n",
        "\n",
        "\t\t\t\t# check if the previous' end time is close to current note\n",
        "\t\t\t\t# if it's not in threshold, this is just a singular note\n",
        "\t\t\t\tif abs(previous_tone_end - note.absoluteStop) <= note.threshold_limit:\n",
        "\t\t\t\t\t# current note's end is close to previous end, check if both start\n",
        "\t\t\t\t\t# and end are close\n",
        "\t\t\t\t\tif previous_tone.is_close(note):\n",
        "\t\t\t\t\t\t# in the event that we need to make a new chord,\n",
        "\t\t\t\t\t\t# we need to save the index of the previous_tone,\n",
        "\t\t\t\t\t\t#create a chord, and insert it back to original position\n",
        "\t\t\t\t\t\tif previous_tone.is_note():\n",
        "\t\t\t\t\t\t\tchord = Chord()\n",
        "\t\t\t\t\t\t\tchord.add_note(previous_tone)\n",
        "\t\t\t\t\t\t\tchord.add_note(note)\n",
        "\t\t\t\t\t\t\tsaveIndex = self.tones.index(previous_tone)\n",
        "\t\t\t\t\t\t\tself.tones.pop(saveIndex)\n",
        "\t\t\t\t\t\t\tself.tones.insert(saveIndex, chord)\n",
        "\t\t\t\t\t\t\tbreak\n",
        "\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\tprevious_tone.add_note(note)\n",
        "\t\t\t\t\t\t\tbreak\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tself.tones.append(note)\n",
        "\t\t\t\t\tbreak\n",
        "\n",
        "class ToneFrequency:\n",
        "\tdef __init__(self, song):\n",
        "\t\tself.song = song\n",
        "\t\tself.frequency_of_all_notes = self.get_all_note_frequency()\n",
        "\t\tself.frequency_of_only_chords = self.get_frequency_only_chords()\n",
        "\t\tself.plot_get_frequency_only_chords()\n",
        "\n",
        "\tdef get_all_note_frequency(self):\n",
        "\t\tfrequencies = defaultdict(int)\n",
        "\t\tfor tone in self.song.tones:\n",
        "\t\t\tif tone.is_note():\n",
        "\t\t\t\tfrequencies[tone.notePlayed] += 1\n",
        "\t\t\telse:\n",
        "\t\t\t\tfor note in tone.notes_in_chord:\n",
        "\t\t\t\t\tfrequencies[note.notePlayed] += 1\n",
        "\t\treturn frequencies\n",
        "\n",
        "\n",
        "\tdef get_frequency_only_chords(self):\n",
        "\t\tfrequencies = defaultdict(int)\n",
        "\t\tfor tone in self.song.tones:\n",
        "\t\t\tif tone.is_chord():\n",
        "\t\t\t\tnotes = tuple(note.notePlayed for note in tone.notes_in_chord)\n",
        "\t\t\t\tfrequencies[notes] += 1\n",
        "\n",
        "\t\treturn frequencies\n",
        "\n",
        "\n",
        "\tdef plot_get_frequency_only_chords(self):\n",
        "\t\tD = self.frequency_of_only_chords\n",
        "\n",
        "\t\tplt.bar(range(len(D)), list(D.values()), align='center')\n",
        "\t\tplt.xticks(range(len(D)), list(D.keys()))\n",
        "\t\t# # for python 2.x:\n",
        "\t\t# plt.bar(range(len(D)), D.values(), align='center')  # python 2.x\n",
        "\t\t# plt.xticks(range(len(D)), D.keys())  # in python 2.x\n",
        "\n",
        "\t\tplt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from mido import MidiFile\n",
        "from mido.midifiles.units import tempo2bpm, bpm2tempo, tick2second, second2tick\n",
        "# from midiUtils import Utils, Tone, Note, Chord, Song\n",
        "#from toneFrequency import ToneFrequency\n",
        "\n",
        "\n",
        "util = Utils()\n",
        "\n",
        "mid = MidiFile(MIDI_file_to_analyze)\n",
        "# mid = MidiFile('./whenTheSaintsLeftHandMelody/wtsgmi5.mid')\n",
        "print((mid.ticks_per_beat))\n",
        "# print(mid.ticks_per_beat, 1000)\n",
        "# print(mid.tracks)\n",
        "# exit()\n",
        "tempoPerMinute = 500000\n",
        "totalNotes = list()\n",
        "song = Song()\n",
        "for i, track in enumerate(mid.tracks):\n",
        "    print('Track {}: {}'.format(i, track.name))\n",
        "    cumulative_time = 0\n",
        "    currently_played_notes = dict()\n",
        "\n",
        "    for msg in track:\n",
        "      try: \n",
        "        if not msg.is_meta:\n",
        "          cumulative_time += tick2second(msg.time, mid.ticks_per_beat, tempoPerMinute)\n",
        "          message_note = util.note_number_to_letter(msg.note)\n",
        "\n",
        "          if message_note in currently_played_notes:\n",
        "            absoluteStart, velocityStart = currently_played_notes.pop(message_note)\n",
        "            note = Note(absoluteStart, cumulative_time, message_note, velocityStart, msg.velocity)\n",
        "            song.add_note(note)\n",
        "          else:\n",
        "            currently_played_notes[message_note] = (cumulative_time, msg.velocity)\n",
        "      except:\n",
        "        continue  \n",
        "    # print(len(song.tones))\n",
        "    # song.sort_by_start_of_tone()\n",
        "    for tone in song.tones:\n",
        "    \tprint(tone)\n",
        "    frequencies = ToneFrequency(song)\n",
        "    print(frequencies.frequency_of_all_notes)\n",
        "    print(frequencies.frequency_of_only_chords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "mmmoUE56-6yn"
      },
      "source": [
        "#@title Pydot Graph\n",
        "pattern = midi.read_midifile(MIDI_file_to_analyze)\n",
        "\n",
        "notes = {NOTE_NAME_MAP_SHARP[name]: name.replace('s', '#').replace('_', '')\n",
        "         for name in NOTE_NAME_MAP_SHARP}\n",
        "\n",
        "l = pattern[0]\n",
        "\n",
        "tracks = []\n",
        "\n",
        "for track in pattern:\n",
        "    x = list()\n",
        "    y = list()\n",
        "    t = 0\n",
        "\n",
        "    for ev in track:\n",
        "        t += ev.tick\n",
        "        if type(ev) == midi.events.NoteOnEvent:\n",
        "            pitch, vel = ev.data\n",
        "            if vel > 0:\n",
        "                y.append(pitch)\n",
        "                x.append(t)\n",
        "\n",
        "    if len(x) > 0:\n",
        "        tracks.append((x, y))\n",
        "\n",
        "\n",
        "colors = ['orange', 'green', 'red']\n",
        "n = 0\n",
        "for track in tracks:\n",
        "    G = nx.DiGraph()\n",
        "    for i in range(len(track[1])-1):\n",
        "        G.add_edge(notes[track[1][i]],\n",
        "                   notes[track[1][i+1]],\n",
        "                   color=colors[n])\n",
        "\n",
        "        G.add_node(notes[track[1][i]],\n",
        "                   color=colors[n])\n",
        "\n",
        "        G.add_node(notes[track[1][i+1]],\n",
        "                   color=colors[n])\n",
        "\n",
        "    nx.drawing.nx_pydot.write_dot(G, \"g%s.dot\" % n)\n",
        "    n += 1\n",
        "\n",
        "nx.draw_networkx(G)\n",
        "#plt.figure(figsize=(19, 10), dpi=300)\n",
        "plt.savefig('Dot_Graph.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIT-OaE9praL",
        "cellView": "form"
      },
      "source": [
        "#@title Generate and plot MIDI file's Parson's code and contour.\n",
        "length_of_the_code_and_contour_in_notes = 70 #@param {type:\"slider\", min:10, max:2000, step:10}\n",
        "code_and_contour_start_offset_in_notes = 0 #@param {type:\"slider\", min:0, max:1000, step:10}\n",
        "\n",
        "#!/usr/bin/env python\n",
        "\n",
        "# https://github.com/snus-kin/parsons-code\n",
        "\n",
        "\"\"\"\n",
        "    Take a midi file and convert it to parsons code, with a limit and offset\n",
        "\"\"\"\n",
        "\n",
        "def midi_to_parsons(midifile, limit=code_and_contour_start_offset_in_notes + length_of_the_code_and_contour_in_notes, offset=code_and_contour_start_offset_in_notes):\n",
        "    \"\"\"\n",
        "        Input: midifile (string) = A midi file path\n",
        "               limit    (int)    = How long is the parsons code\n",
        "               offset   (int)    = How many notes in do we start\n",
        "        Output: parsons (string) = A string containing a parsons code length\n",
        "                                   limit at an offset from the start of the file\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    parsons = \"\"\n",
        "    for message in mido.MidiFile(midifile):\n",
        "        if \"note_on\" in str(message) and offset == 0:\n",
        "            if parsons == \"\":\n",
        "                # initialise list\n",
        "                prev = message.note\n",
        "                parsons += \"*\"\n",
        "\n",
        "            # simple comparison\n",
        "            elif message.note > prev:\n",
        "                parsons += \"U\"\n",
        "                prev = message.note\n",
        "            elif message.note < prev:\n",
        "                parsons += \"D\"\n",
        "                prev = message.note\n",
        "            elif message.note == prev:\n",
        "                parsons += \"R\"\n",
        "                prev = message.note\n",
        "\n",
        "            #increment count\n",
        "            count += 1\n",
        "            if count >= limit:\n",
        "                break\n",
        "        elif \"note_on\" in str(message):\n",
        "            offset -= 1\n",
        "\n",
        "    return parsons\n",
        "\n",
        "code = midi_to_parsons(MIDI_file_to_analyze)\n",
        "\n",
        "#print(code)\n",
        "\n",
        "\"\"\" Parsons code to contour plot \"\"\"\n",
        "\n",
        "def contour(code):\n",
        "    print('Song Parson Code is:')\n",
        "    print(code)\n",
        "    print('')\n",
        "    if code[0] != \"*\":\n",
        "        raise ValueError(\"Parsons Code must start with '*'\")\n",
        "\n",
        "    contour_dict = {}\n",
        "    pitch = 0\n",
        "    index = 0\n",
        "\n",
        "    maxp = 0\n",
        "    minp = 0\n",
        "\n",
        "    contour_dict[(pitch, index)] = \"*\"\n",
        "\n",
        "    for point in code:\n",
        "        if point == \"R\":\n",
        "            index += 1\n",
        "            contour_dict[(pitch, index)] = \"-\"\n",
        "\n",
        "            index += 1\n",
        "            contour_dict[(pitch, index)] = \"*\"\n",
        "        elif point == \"U\":\n",
        "            index += 1\n",
        "            pitch -= 1\n",
        "            contour_dict[(pitch, index)] = \"/\"\n",
        "\n",
        "            index += 1\n",
        "            pitch -= 1\n",
        "            contour_dict[(pitch, index)] = \"*\"\n",
        "\n",
        "            if pitch < maxp:\n",
        "                maxp = pitch\n",
        "        elif point == \"D\":\n",
        "            index += 1\n",
        "            pitch += 1\n",
        "            contour_dict[(pitch, index)] = \"\\\\\"\n",
        "\n",
        "            index += 1\n",
        "            pitch += 1\n",
        "            contour_dict[(pitch, index)] = \"*\"\n",
        "\n",
        "            if pitch > minp:\n",
        "                minp = pitch\n",
        "\n",
        "    for pitch in range(maxp, minp+1):\n",
        "        line = [\" \" for _ in range(index + 1)]\n",
        "        for pos in range(index + 1):\n",
        "            if (pitch, pos) in contour_dict:\n",
        "                line[pos] = contour_dict[(pitch, pos)]\n",
        "\n",
        "\n",
        "        print(\"\".join(line))\n",
        "\n",
        "\n",
        "contour(code)    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}