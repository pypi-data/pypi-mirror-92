"""RNASeq pipeline

Affiliation: Institut Pasteur @ 2016-2020

This pipeline is part of Sequana software (sequana.readthedocs.io)
"""
import glob
import os
import shutil
import sequana
from os.path import join
from sequana import snaketools as sm
import sequana.featurecounts as fc

configfile: "config.yaml"

manager = sm.PipelineManager("rnaseq", config)
manager.setup(globals(), mode="warning")


def error(msg):
    from sequana.pipelines_common import error as err
    err(msg, "rnaseq")


# Generic include of some dynamic modules
exec(open(sequana.modules["bowtie1_mapping_dynamic"], "r").read())
exec(open(sequana.modules["bowtie1_index_dynamic"], "r").read())
exec(open(sequana.modules["bowtie2_mapping_dynamic"], "r").read())
exec(open(sequana.modules["bowtie2_index_dynamic"], "r").read())
exec(open(sequana.modules["fastqc_dynamic"], "r").read())
exec(open(sequana.modules["dynamic_unpigz"], "r").read())
exec(open(sequana.modules["mark_duplicates_dynamic"], "r").read())
exec(open(sequana.modules["feature_counts_dynamic"], "r").read())


__data__input = manager.getrawdata()



__strand__summary = "outputs/strand_summary.csv"
rule rnaseq:
    input: "multiqc/multiqc_report.html", ".sequana/rulegraph.svg", __strand__summary,


# Make sure it is absolute
genome_directory = os.path.abspath(config["general"]["genome_directory"])
genome_name = genome_directory.rsplit("/", 1)[1]

__prefix_name__ = genome_directory + "/" + genome_name
__fasta_file__ = __prefix_name__ + ".fa"
__gff_file__   = __prefix_name__ + ".gff"


# do we have several feature, if so, we need to build a custom GFF file
if config['general']['custom_gff']:
    __gff_file__   = config['general']['custom_gff']
assert os.path.exists(__gff_file__)

# check existence of fasta and gff before starting;
for this in [__fasta_file__, __gff_file__]:
    if os.path.exists(this) is False:
        raise IOError("File {} not found".format(__fasta_file__))


# create sequence dict file. Looks like it is used for picard tools.
# FIXME: see if we cannot simplify this rule and merge it with the picard rule
__create_sequence_dictionary__reference = __fasta_file__
__create_sequence_dictionary__output =    __fasta_file__ + ".dict"
__create_sequence_dictionary__log =       "logs/indexing/create_sequence_dictionary.log"
include: sm.modules["create_sequence_dictionary"]
expected_output.extend([__create_sequence_dictionary__output])


do_indexing = manager.config.general.indexing
force_indexing = manager.config.general.force_indexing
# =========================================================================== bowtie1

msg_error_indexing_exists = "Indexing file for {} exists already ({}). "+\
    "Set general::indexing to False or general::force_indexing to True "+\
    "in the config file"
msg_error_indexing_notfound = "Indexing file for {} not found ({}). "+\
    "Set general::indexing to True in the config file"

if manager.config.general.aligner == "bowtie1":
    __bowtie1_index_ref__output_done   = genome_directory + f"/bowtie1/{genome_name}.1.ebwt"
    __bowtie1_index__ = genome_directory + f"/bowtie1/{genome_name}"

    if os.path.exists(__bowtie1_index_ref__output_done) and do_indexing is False:
        pass # index exists, no need to do it, everything should be fine
    elif (os.path.exists(__bowtie1_index_ref__output_done) and do_indexing and force_indexing) or \
        (os.path.exists(__bowtie1_index_ref__output_done) is False and do_indexing):
        # if the file does not exists and we ask for the indexing
        # OR if the file exists but we want to overwrite it 
        __bowtie1_index_ref__fasta         = __fasta_file__
        #__bowtie1_index_ref__output_done   # defined above
        __bowtie1_index_ref__output_prefix =    genome_directory + f"/bowtie1/{genome_name}"
        __bowtie1_index_ref__log           = "logs/indexing/bowtie1_genome.log"
        include: bowtie1_index_dynamic("ref")
    #elif os.path.exists(__bowtie1_index_ref__output_done) and do_indexing and force_indexing is False:
    #    error(msg_error_indexing_exists.format("bowtie1", __bowtie1_index_ref__output_done))
    elif os.path.exists(__bowtie1_index_ref__output_done) is False and do_indexing is False:
        error(msg_error_indexing_notfound.format("bowtie1", __bowtie1_index_ref__output_done))

if manager.config.general.contaminant_file and manager.config.general.rRNA_feature:
    error("Either set contaminant_file or rRNA_feature in the config file, not both.")

# =========================================================================== rRNA genome
if manager.config.general.contaminant_file:
    __bowtie1_index_rna__fasta = config['general']["genome_directory"] + os.sep + config["general"]["contaminant_file"]
    if os.path.exists(__bowtie1_index_rna__fasta) is False:
        error("File {} does not exists. Check your config file".format(__bowtie1_index_rna__fasta))
elif manager.config.general.rRNA_feature:
    # extract rRNA feature from GFF and get corresponding fasta
    # and gff. if no match for rRNA, save empty fasta as AAAAAAAAAAA
    __extract_fasta_from_bed__input =       __fasta_file__
    __extract_fasta_from_bed__gff =         __gff_file__
    __extract_fasta_from_bed__feature =     config["general"]["rRNA_feature"]
    __extract_fasta_from_bed__output =          __prefix_name__ + "_rRNA.fa"
    __extract_fasta_from_bed__output_features = __prefix_name__ + "_rRNA.gff"
    __extract_fasta_from_bed__log =             "logs/indexing/get_rRNA.log"
    include: sm.modules["extract_fasta_from_bed"]

    # This is fast, so we do it again
    __bowtie1_index_rna__fasta = __extract_fasta_from_bed__output

if manager.config.general.contaminant_file or manager.config.general.rRNA_feature:
    __bowtie1_index_rna__output_done = __prefix_name__ + "_rRNA.1.ebwt"
    __bowtie1_index_rna__output_prefix = __prefix_name__ + "_rRNA"
    __bowtie1_index_rna__log = "logs/bowtie1_indexing/bowtie_rRNA.log"
    include: bowtie1_index_dynamic("rna")
    __RNA_index__ = __bowtie1_index_rna__output_prefix

# ============================================================================ bowtie2 index

if manager.config.general.aligner == "bowtie2":
    if config['bowtie2_mapping_ref']['genome_size_larger_than_4gb']:
        bt2_ext = "bt2l"
    else: 
        bt2_ext = "bt2"

    # These two variables are used elsewhere and in the rule below
    __bowtie2_index_ref__output_done   = genome_directory + f"/bowtie2/{genome_name}.1.{bt2_ext}"
    __bowtie2_index__ = genome_directory + f"/bowtie2/{genome_name}"

    if os.path.exists(__bowtie2_index_ref__output_done) and do_indexing is False:
        pass # index exists, no need to do it, everything should be fine
    elif (os.path.exists(__bowtie2_index_ref__output_done) and do_indexing and force_indexing) or \
        (os.path.exists(__bowtie2_index_ref__output_done) is False and do_indexing):
        __bowtie2_index_ref__fasta =            __fasta_file__
        #__bowtie2_index_ref__output_done   # defined above
        __bowtie2_index_ref__output_prefix =    genome_directory + f"/bowtie2/{genome_name}"
        __bowtie2_index_ref__log = "logs/indexing/bowtie2_genome.log"
        include: bowtie2_index_dynamic("ref")
    elif os.path.exists(__bowtie2_index_ref__output_done) is False and do_indexing is False:
        error(msg_error_indexing_notfound.format("bowtie2", __bowtie2_index_ref__output_done))

elif manager.config.general.aligner  == "star":
    __star_index__output_done = genome_directory +  "/star/SAindex"
    __star_dir__ = genome_directory + "/star"
    if os.path.exists(__star_index__output_done) and do_indexing is False:
        pass # index exists, no need to do it, everything should be fine
    elif (os.path.exists(__star_index__output_done) and do_indexing and force_indexing) or \
        (os.path.exists(__star_index__output_done) is False and do_indexing):
        __star_index__fasta =  __fasta_file__
        __star_index__output_dir =  genome_directory + "/star"
        __star_index__log = "logs/indexing/star_genome.log"
        include: sm.modules["star_index"]
    elif os.path.exists(__star_index__output_done) is False and do_indexing is False:
        error(msg_error_indexing_notfound.format("star", __star_index__output_done))

elif manager.config.general.aligner == "salmon":
    __salmon_index__output_done = genome_directory + "/salmon/salmon.done"
    __salmon_index__genome_dir =  genome_directory + "/salmon"
    if os.path.exists(__salmon_index__output_done) and do_indexing is False:
        pass # index exists, no need to do it, everything should be fine
    elif (os.path.exists(__salmon_index__output_done) and do_indexing and force_indexing) or \
        (os.path.exists(__salmon_index__output_done) is False and do_indexing):
        __salmon_index__fasta_input =  __fasta_file__
        __salmon_index__gff_input =  __gff_file__
        __salmon_index__log = "logs/indexing/salmon.log"
        include: sm.modules["salmon_index"]
    elif os.path.exists(__salmon_index__output_done) is False and do_indexing is False:
        error(msg_error_indexing_notfound.format("salmon", __salmon_index__output_done))



# FASTQC on input data set

if not config['fastqc']['skip_fastqc_samples']:
    __fastqc_samples__input_fastq = __data__input
    __fastqc_samples__output_done = manager.getname("fastqc_samples", ".done")
    __fastqc_samples__wkdir       = manager.getwkdir("fastqc_samples")
    __fastqc_samples__log         = "%s/fastqc_samples/fastqc.log" % manager.sample
    include: fastqc_dynamic("samples", manager)
    expected_output.extend(expand(__fastqc_samples__output_done, sample=manager.samples))

if manager.config.cutadapt.do:
    adapter_tool = manager.config.cutadapt.tool_choice

    from sequana.adapters import _get_registered_adapters as registered
    from sequana.adapters import get_sequana_adapters

    # Users may provide TruSeq, Nextera, PCRFree or other registered adapters
    fwd = manager.config.cutadapt.fwd
    if isinstance(fwd, str) and fwd in registered():
        filename = "file:"+ get_sequana_adapters(fwd, "fwd")
        manager.config.cutadapt.fwd = filename

    rev = manager.config.cutadapt.rev
    if isinstance(rev, str) and rev in registered():
        filename = "file:"+ get_sequana_adapters(rev, "revcomp")
        manager.config.cutadapt.rev = filename

    if adapter_tool in ["cutadapt", "atropos"]:
        adapter_tool = "cutadapt"
        __cutadapt__input_fastq = __data__input
        __cutadapt__wkdir = manager.getwkdir("cutadapt")
        __cutadapt__output = [manager.getname("cutadapt", "_R1_.cutadapt.fastq.gz")]
        if manager.paired:
            __cutadapt__output += [manager.getname("cutadapt", "_R2_.cutadapt.fastq.gz")]

        # Set the fwd and rev adapters
        __cutadapt__fwd = manager.config.cutadapt.fwd
        __cutadapt__rev = manager.config.cutadapt.rev

        __cutadapt__design = manager.config.cutadapt.design_file
        __cutadapt__design_adapter = manager.config['cutadapt']['adapter_choice']
        __cutadapt__options = manager.config.cutadapt.options
        __cutadapt__mode = manager.config.cutadapt.mode
        __cutadapt__log = "%s/logs/cutadapt/cutadapt.txt" % manager.sample
        __cutadapt__sample = manager.sample
        __clean_fastq__output = __cutadapt__output
        include: sm.modules["cutadapt"]
else:
    __clean_fastq__output = __data__input


if manager.config.fastq_screen.do:

    # if users has not changed the fastq_screen conf file, we can build the phix
    if os.path.exists("fastq_screen.conf"):
        if "DATABASE\tphiX174\t.genomes/phiX174/phiX174 BOWTIE2\n" in open("fastq_screen.conf").readlines():
            shell("mkdir -p .genomes/phiX174")

            # copy the phiX174.fa
            from sequana.pipelines_common import get_pipeline_location as getpath
            phix = getpath("rnaseq") + "/phiX174.fa"

            # build index
            shell("cp {} .genomes/phiX174".format(phix))
            shell("cd .genomes/phiX174 ; bowtie2-build -f phiX174.fa phiX174 1> phiX174.log 2> phiX174.err; cd ..")
            shell("cd .genomes/phiX174 ; samtools faidx phiX174.fa; cd ..")
    # TODO:
    # check existence of all indexing file for each entry in fastqscree

    # Fastq Screen
    __fastq_screen__input = __clean_fastq__output
    __fastq_screen__logs = manager.getname("fastq_screen", ".logs")

    # hack could be improved TODO
    __fastq_screen__output = [x.replace(".fastq.gz", "_screen.txt") for x in __fastq_screen__input]

    include: sm.modules["fastq_screen"]

    if manager.config.fastq_screen.report:
        __fastq_screen_report__input = __fastq_screen__output
        __fastq_screen_report__figure = manager.getname("fastq_screen", "_report.svg")
        __fastq_screen_report__logs =  manager.getname("fastq_screen", "report.logs")
        include: sm.modules["fastq_screen_report"]
        expected_output.extend(expand(__fastq_screen_report__figure, sample=manager.samples))
    else:
        expected_output.extend(expand(__fastq_screen__output, sample=manager.samples))



# FASTQC on input data set
__fastqc_filtered__input_fastq = __clean_fastq__output
__fastqc_filtered__output_done = manager.getname("fastqc_filtered", ".done")
__fastqc_filtered__wkdir       = manager.getwkdir("fastqc_filtered")
__fastqc_filtered__log         = "%s/fastqc_filtered/fastqc.log" % manager.sample
include: fastqc_dynamic("filtered", manager)
expected_output.extend(expand(__fastqc_filtered__output_done, sample=manager.samples))



# Decompress fastq.gz file before running bowtie1
if manager.config.cutadapt.do:
    __unpigz_R1__input = manager.getname("cutadapt", "_R1_.cutadapt.fastq.gz")
    __unpigz_R1__output = manager.getname("cutadapt", "_R1_.cutadapt.fastq")
else:
    __unpigz_R1__input = __data__input
    __unpigz_R1__output = manager.getname("cutadapt", "_R1_.cutadapt.fastq")


include: dynamic_unpigz("R1", manager)
__unpigz__output = [__unpigz_R1__output]
"""With paired data, alignement on rRNA leads to 0% alignment if we use R1 and
R2. If we use R1 only, the percentage is >0. First reason is that reads are not
trimmed properly. In truth, bowtie2 supports local alignments which means it can
soft-clip non-matching (=adapter) content while still align the local part of
the read that matches the reference. With Bowtie1 the read will probably go
unaligned due to the many mismatches. So we do not include R2 from version
v0.9.14.
"""


if manager.config.general.rRNA_feature or manager.config.general.contaminant_file:
    # rRNA
    __bowtie1_mapping_rna__input = __unpigz__output
    __bowtie1_mapping_rna__index_done = __bowtie1_index_rna__output_done
    __bowtie1_mapping_rna__bam = manager.getname("bowtie1_mapping_rna", ".bam")
    __bowtie1_mapping_rna__sort = manager.getname("bowtie1_mapping_rna", ".sorted.bam")
    __bowtie1_mapping_rna__prefix_index = __RNA_index__
    __bowtie1_mapping_rna__stdout = manager.getname("bowtie1_mapping_rna", "_rRNA.out")
    __bowtie1_mapping_rna__stderr = manager.getname("bowtie1_mapping_rna", "_rRNA.err")

    include: bowtie1_mapping_dynamic("rna", manager)
    expected_output.extend(expand(__bowtie1_mapping_rna__sort, sample=manager.samples))


if manager.config.general.aligner == "bowtie1":
    # Mapper bowtie 1
    __bowtie1_mapping_ref__input = __unpigz__output
    __bowtie1_mapping_ref__index_done = __bowtie1_index_ref__output_done
    __bowtie1_mapping_ref__bam = manager.getname("bowtie1_mapping_ref", ".bam")
    __bowtie1_mapping_ref__sort = manager.getname("bowtie1_mapping_ref", ".sorted.bam")
    __bowtie1_mapping_ref__prefix_index = __bowtie1_index__
    __bowtie1_mapping_ref__stdout = manager.getname("bowtie1_mapping_ref", ".out")
    __bowtie1_mapping_ref__stderr = manager.getname("bowtie1_mapping_ref", ".err")
    include: bowtie1_mapping_dynamic("ref", manager)
    expected_output.extend(expand(__bowtie1_mapping_ref__sort, sample=manager.samples))
    __mapping_output = __bowtie1_mapping_ref__sort
elif manager.config.general.aligner == "bowtie2":
    # mapping on ref
    __bowtie2_mapping_ref__input = __clean_fastq__output
    __bowtie2_mapping_ref__index_done = __bowtie2_index_ref__output_done
    __bowtie2_mapping_ref__sort = manager.getname("bowtie2_mapping_ref", ".sorted.bam")
    __bowtie2_mapping_ref__bam = manager.getname("bowtie2_mapping_ref", ".bam")
    __bowtie2_mapping_ref__logs_err = manager.getname("bowtie2_mapping_ref", ".err")
    __bowtie2_mapping_ref__logs_out = manager.getname("bowtie2_mapping_ref", ".out")
    __bowtie2_mapping_ref__options = config["bowtie2_mapping_ref"]["options"]
    __bowtie2_mapping_ref__prefix_index = __bowtie2_index__
    include: bowtie2_mapping_dynamic("ref", manager)
    expected_output.extend(expand(__bowtie2_mapping_ref__sort, sample=manager.samples))
    __mapping_output = __bowtie2_mapping_ref__sort
elif manager.config.general.aligner == "star":
    # Mapper rna-star
    __star_mapping__input = __clean_fastq__output
    __star_mapping__index_done = __star_index__output_done
    __star_mapping__index = __star_dir__
    __star_mapping__ref = __fasta_file__
    __star_mapping__logs = manager.getname("star_mapping", ".logs")
    __star_mapping__output_prefix1 = manager.getname("star_mapping", "_init_")
    __star_mapping__output_prefix2 = manager.getname("star_mapping", "_")
    __star_mapping__read_groups = ""
    __star_mapping__sort = manager.getname("star_mapping", "_Aligned.sortedByCoord.out.bam")
    __star_mapping__genome_dir = manager.getname("star_mapping", "_star_2nd_pass")
    __star_mapping__splice_file = manager.getname("star_mapping", "_init_SJ.out.tab")
    include: sm.modules["star_mapping"]
    expected_output.extend(expand(__star_mapping__sort, sample=manager.samples))
    __mapping_output = __star_mapping__sort
elif manager.config.general.aligner == "salmon":
    __salmon_mapping__input_fastq = __clean_fastq__output
    __salmon_mapping__output_counts = "{sample}/salmon_mapping/{sample}_quant.sf"
    __salmon_mapping__logs = manager.getname("salmon_mapping", ".logs")
    include: sm.modules["salmon_mapping"]
    expected_output.extend(expand(__salmon_mapping__output_counts, sample=manager.samples))
    # There is no BAM created 
    __mapping_output = None

# The input is the output of the mapping 
# Add Read group on BAM files
if manager.config.general.aligner not in ['salmon']:
    __add_read_group__input = __mapping_output
    __add_read_group__output = manager.getname("add_read_group", ".bam")
    __add_read_group__log_err = "%s/logs/AddOrReplaceReadGroups/stderr.logs" % manager.sample
    __add_read_group__log_std ="%s/logs/AddOrReplaceReadGroups/stdout.logs" % manager.sample
    __add_read_group__rg = "ID=%s LB=%s PL=%s PU=%s SM=%s" % (
        manager.sample, manager.sample, manager.config.sequencing.platform,
        manager.config.sequencing.flowcell, manager.sample)
    include: sm.modules["add_read_group"]


# we always add read group so input is the read group output
# output is stored in __final_bam__
# duplicates can be from PCR or if SR, by pure chance.
# if Paired, most likely a PCR origin.
# Mark duplicates
if config["mark_duplicates"]["do"] and manager.config.general.aligner not in ['salmon']:
    __mark_duplicates_ref__input   = __add_read_group__output
    __mark_duplicates_ref__output  = manager.getname("mark_duplicates", ".bam")
    __mark_duplicates_ref__metrics = manager.getname("mark_duplicates", ".metrics")
    __mark_duplicates_ref__log_std = "%s/logs/mark_duplicates/stdout.logs" % manager.sample
    __mark_duplicates_ref__log_err = "%s/logs/mark_duplicates/stderr.logs" % manager.sample
    include: mark_duplicates_dynamic("ref", manager)
    expected_output.extend(expand(__mark_duplicates_ref__output, sample=manager.samples))
    __final_bam__ = __mark_duplicates_ref__output
else:
    __final_bam__ = __add_read_group__output


# generating bigwig files
if manager.config.coverage.do is True and config['general']['aligner'] not in ['salmon']:
    __bamCoverage__input = __final_bam__
    __bamCoverage__log = manager.getname("bamCoverage", ".logs")
    __bamCoverage__output = manager.getname("bamCoverage", ".norm.bw")
    include: sm.modules["bamCoverage"]
    expected_output.extend(expand(__bamCoverage__output, sample=manager.samples))


if manager.config.igvtools.do and config['general']['aligner'] not in ['salmon']:
    # if nothing provided, it must be an empty string
    if manager.config.igvtools.chrom_sizes_file.strip():
        pass
    else:
      config["igvtools"]["chrom_sizes_file"] = __fasta_file__

    __igvtools__input = __final_bam__
    __igvtools__output = manager.getname("igvtools", ".tdf")
    __igvtools__log = manager.getname("igvtools", ".logs")
    include: sm.modules["igvtools"]
    expected_output.extend(expand(__igvtools__output, sample=manager.samples))


# Feature counts from subread suite
if manager.config.general.aligner == "salmon":
    __feature_counts__input = __salmon_mapping__output_counts
else :
    __feature_counts__input = __final_bam__

fc_outdir = "rnadiff/feature_counts/"

if manager.config.feature_counts.do and manager.config.general.aligner not in ['salmon']:
    # Guessing strandness is not always straightfoward; Even when we set it; 
    # collaborators may want to look at the other options. So, we compute
    # everything with the 3 different options of strandness.
    # We will copy one of them based on our criteria, but all 3 will be
    # available

    feature_type = config['feature_counts']['feature']
    if "," in feature_type: # assume this is a custom GFF file
        feature_type = "custom"

    fc_options = " -t {} -g {} ".format(
        feature_type,
        config['feature_counts']['attribute'])

    if config['feature_counts']['extra_attributes']:
        fc_options += " --extraAttributes {} ".format(config['feature_counts']['extra_attributes'])

    # We finally add other options that may overwrite previous options ! as
    # described in the rnaseq pipeline documentation. 
    fc_options += " {} ".format(config['feature_counts']['options'])

    __feature_counts_0__output_count = manager.getname("feature_counts_0", "_feature.out")
    __feature_counts__gff = __gff_file__
    __feature_counts__options = fc_options + " -s 0 "
    if manager.paired:
        __feature_counts__options += " -p "
    __feature_counts_0__log = manager.getname("feature_counts_0", ".logs")
    __feature_counts__threads = config["feature_counts"]["threads"]
    include: feature_counts_dynamic("0", manager)

    __feature_counts_1__output_count = manager.getname("feature_counts_1", "_feature.out")
    __feature_counts_1__log = manager.getname("feature_counts_1", ".logs")
    __feature_counts__options = fc_options + " -s 1"
    if manager.paired:
        __feature_counts__options +=  " -p "
    include: feature_counts_dynamic("1", manager)

    __feature_counts_2__output_count = manager.getname("feature_counts_2", "_feature.out")
    __feature_counts_2__log = manager.getname("feature_counts_2", ".logs")
    __feature_counts__options = fc_options + " -s 2"
    if manager.paired:
        __feature_counts__options +=  " -p "
    include: feature_counts_dynamic("2", manager)

    __guess_strandness__output =expand(fc_outdir + "{sample}_feature.out", sample=manager.samples) 
    rule guess_strandness:
        input:
            fc0= expand(__feature_counts_0__output_count, sample=manager.samples),
            fc1= expand(__feature_counts_1__output_count, sample=manager.samples),
            fc2= expand(__feature_counts_2__output_count, sample=manager.samples)
        output:
            data=__guess_strandness__output,
            summary=__strand__summary
        run:
            # We compute all strandness
            import sequana.featurecounts as fc
            tolerance = config['feature_counts']['tolerance']
            mfc = fc.MultiFeatureCount(rnaseq_folder=".", tolerance=tolerance)
            probable_strand, strand_df = mfc.get_most_probable_strand_consensus()
            strand_df.to_csv(output.summary)
            try:
                mfc.plot_strandness(savefig=True, output_filename="outputs/strand_summary.png")
            except Exception as err:
                logger.warning("Could not create plot_strandness")
                logger.warning("err")

            logger.info("strandness inference: {}".format(probable_strand))
            msg = "This is {probable_strand} data (check in the multiqc report)"
            if probable_strand in [0, 1, 2]:
                choice = probable_strand
                logger.info(msg)
            else:
                logger.warning("Strandness is apparently neither of 0, 1, 2")
                logger.warning("you will need to copy the feature counts files yourself in ./feature_counts")
                choice = -1

            # If user knowns what he/she wants we overwrite the choice
            if "strandness" in config['feature_counts'] and config["feature_counts"]["strandness"]:
                user_choice =  int(config["feature_counts"]["strandness"])
                if user_choice in [0,1,2]:
                    choice = user_choice
                else:
                    logger.error(f"strandness in the config file must be 0,1,2. You gave {user_choice}")

            if choice == 0:
               for filename in input.fc0:
                   shell("cp {} {}".format(filename, fc_outdir))
                   shell("cp {}.summary {}".format(filename, fc_outdir))
            elif choice == 1:
               for filename in input.fc1:
                   shell("cp {} {}".format(filename, fc_outdir))
                   shell("cp {}.summary {}".format(filename, fc_outdir))
            elif choice == 2:
               for filename in input.fc2:
                   shell("cp {} {}".format(filename, fc_outdir))
                   shell("cp {}.summary {}".format(filename, fc_outdir))
            else:
                # if not clear, we copy everything and users should clean up the directory
                for filename in input.fc0:
                    shell("cp {} {}".format(filename, fc_outdir))
                    shell("cp {}.summary {}".format(filename, fc_outdir))
                for filename in input.fc1:
                    shell("cp {} {}".format(filename, fc_outdir))
                    shell("cp {}.summary {}".format(filename, fc_outdir))
                for filename in input.fc2:
                    shell("cp {} {}".format(filename, fc_outdir))
                    shell("cp {}.summary {}".format(filename, fc_outdir))
    expected_output += __guess_strandness__output
elif manager.config.feature_counts.do and manager.config.general.aligner in ['salmon']:

    __salmon_to_features__input = __salmon_mapping__output_counts
    __salmon_to_features__output = fc_outdir + "{sample}_feature.out"
    rule salmon_to_features:
        input: __salmon_to_features__input
        output: __salmon_to_features__output
        params:
            gff=__gff_file__
        shell:
            """sequana salmon --input {input} --output {output} --gff {params.gff} --attribute ID   """
    expected_output += expand(__salmon_to_features__output, sample=manager.samples)



# FIXME do we need the mark_duplicates for RNASEQC2 ? is it compulsary ?
if config["rnaseqc"]["do"]:
    __reorderSam__input_sam = __final_bam__
    __reorderSam__input_genome = __fasta_file__
    __reorderSam__logs = manager.getname("reorderSam", ".logs")
    __reorderSam__output = manager.getname("reorderSam", "_reorder.bam")
    include: sm.modules["reorderSam"]
    #expected_output.extend(expand(__reorderSam__output, sample=manager.samples))

    # Define input of the rnaseqc rule.
    if config["mark_duplicates"]['do']:
        __rnaseqc__input_bam = __mark_duplicates_ref__output
    else:
        __rnaseqc__input_bam = __reorderSam__input_sam

    # for multiqc, important that output directories are called rnaseqc
    #__rnaseqc__input_genome = __fasta_file__
    if os.path.exists(config['rnaseqc']['gtf_file']):
        __rnaseqc__input_gtf = config['rnaseqc']['gtf_file']
    elif os.path.exists(genome_directory + os.sep + config['rnaseqc']['gtf_file']):
        __rnaseqc__input_gtf = genome_directory + os.sep + config['rnaseqc']['gtf_file']
    else:
        error("Could not find {} locally or in {}".format(
            config['rnaseqc']['gtf_file'],
            config['general']['genome_directory']
        ))
    __rnaseqc__params_directory = "{sample}/rnaseqc"
    __rnaseqc__logs = "{sample}/rnaseqc/{sample}.log"
    __rnaseqc__params_sample = "{sample}"
    __rnaseqc__output_metrics = "{sample}/rnaseqc/{sample}.metrics.tsv"
    include: sm.modules["rnaseqc"]
    expected_output.extend(expand(__rnaseqc__output_metrics, sample=manager.samples))


# !Reset expected_output variable after multiqc
# Hack while waiting for a more general multiqc rules

# Multiqc rule
__multiqc__input = expected_output
__multiqc__input_dir = "."
__multiqc__logs = "multiqc/multiqc.log"
__multiqc__output = "multiqc/multiqc_report.html"
if config['multiqc']['config_file']:
    __multiqc__options = " -c " + config['multiqc']['config_file'] + " "+config['multiqc']['options']
else :
    __multiqc__options = config['multiqc']['options']
__multiqc__output_dir = config['multiqc']['output_directory']

include: sm.modules["multiqc"]
#final_output.extend([__multiqc__output])


# Include rule graph for each sample
__rulegraph__input = manager.snakefile
__rulegraph__output = ".sequana/rulegraph.svg"
__rulegraph__mapper = {"multiqc": "../multiqc/multiqc_report.html"}
include: sm.modules['rulegraph']


# Add Conda
__conda__output = "requirements.txt"
include: sm.modules['conda']   # Create requirements.txt(dependencies)
#final_output.extend([__conda__output])


# Those rules takes a couple of seconds so no need for a cluster
localrules: conda, rulegraph


onsuccess:
    # Create plots about stats
    from sequana import logger
    from sequana.gff3 import GFF3
    from sequana.pipelines_common import get_pipeline_location as getpath
    from sequana import BAM
    from sequana.modules_report.summary import SummaryModule2

    logger.level = "INFO"
    manager.teardown(
        extra_files_to_remove=["fastq_screen.conf", "requirements.txt"],
        extra_dirs_to_remove=[".genomes", "tmp", "logs"])
    manager.clean_multiqc(__multiqc__output)

    #manager.plot_stats(N=len(manager.samples))

    # copy feature counts

    try: # should be created already
        os.mkdir("rnadiff")
        os.mkdir("rnadiff/feature_counts")
    except:pass

    try:os.mkdir("rnadiff")
    except:pass

    logger.info("Building input files for rnadiff analysis")
    # in theory, the options used in the feature counts should be used here 
    # features counts -t option specifies the feature type from he GTF/GFF
    # annotation e.g. exon, gene the -g option specify the attributes to be 
    # found in the GFF. e.g. ID, locus_id, etc 
    gff = GFF3(__gff_file__)
    genetic_type = feature_type  # do not use config['feature_counts'] to take into account the custom case
    attribute = config['feature_counts']['attribute']
    gff.create_files_for_rnadiff("rnadiff/input", genetic_type=genetic_type, 
        ID=attribute, fields=[attribute])
    script = """
from sequana.gff3 import GFF3
gff = GFF3("{}")
gff.create_files_for_rnadiff("input", genetic_type="{}", ID="{}", fields={})
"""
    script = script.format(__gff_file__, genetic_type, attribute, [attribute])
    with open("rnadiff/build_input_files.py", "w") as fout:
        fout.write(script)

    sharedir = getpath("rnaseq")
    if config['rnadiff']['mode'] == "one_factor":
        filename = sharedir + os.sep + "rnadiff_one_factor.R"
        outname = "rnadiff/{}".format("rnadiff_one_factor.R")
        if os.path.exists(outname) is False:
            shutil.copy(filename, outname)
    else:
        filename = sharedir + os.sep + "rnadiff_GLM.R"
        outname = "rnadiff/{}".format("rnadiff_GLM.R")
        if os.path.exists(filename) is False:
            shutil.copy(filename, outname)

    # depending on users choice, we copy the relevant feature counts
    if manager.config.general.aligner == 'salmon':
        tocopy = expand(__salmon_mapping__output_counts, sample=manager.samples)
        shell("cp {} ./rnadiff/feature_counts/ ".format(" ".join(tocopy)))

    # now we build a unique file. Probably not required anywhere
    def create_single_feature_file():
        import glob
        filenames = glob.glob("rnadiff/feature_counts/*_feature.out")
        import pandas as pd
        df = pd.read_csv(filenames[0], sep="\t", skiprows=1)
        for filename in filenames[1:]:
            other_df = pd.read_csv(filename, sep="\t", skiprows=1)
            df = pd.merge(df, other_df)
        df.to_csv("rnadiff/feature_counts/all_features.out",sep="\t")
    create_single_feature_file()

    with open("rnadiff/create_target.py", "w") as fout:
        from sequana_pipelines.rnaseq import create_target
        with open(create_target.__file__, "r") as fin:
            fout.write(fin.read())


    # THE HTML REPORT is defined hereafter
    #
    from sequana_pipelines import rnaseq
    data = {"name": "rnaseq",
            "rulegraph": __rulegraph__output,
            "stats": "stats.txt",
            "pipeline_version": rnaseq.version}


    try:
        import pandas as pd
        df = pd.read_csv(__strand__summary)
        guess = df['strand'].value_counts().idxmax()
        names = {0: 'stranded', 1: 'unstranded', 2: 'reversely stranded'}
        guess = names[guess]
    except Exception as err:
        logger.warning(err)
        guess = "?"

    intro ="""
    <h2>Overview</h2>
    <p>
    The rnaseq pipeline maps the reads on the provided reference using {}. Features counts were
    extracted and are available in <a href="./rnadiff/feature_counts">feature counts</a> directory; ready to use for differential gene analysis. 
    </p>

    <p>A <a href="multiqc/multiqc_report.html">multiqc report</a> is available, where various QC and mapping quality plots can be visualised.
    </p>

    <p>Here below is a QC plot related to the strandness found for each samples. The red dotted lines indicate a tolerance. The 0.5 vertical line correspond to an <b>unstranded</b> case. A value close to 0 indicates a <b>reversely stranded</b> case, and a value close to 1 indicates a <b>stranded</b> case.
    """.format(config["general"]['aligner'], guess)

    if "strandness" in config['feature_counts'] and config["feature_counts"]["strandness"]:
        choice = config["feature_counts"]["strandness"]
        intro += "User decided to set strandness to: {} </p>".format(choice)
    else:
        intro += "Strandness was guessed from the data. </p>"

    image = SummaryModule2.png_to_embedded_png("dummy", "outputs/strand_summary.png", 
                 style="width:80%; height:40%")
    intro+=image
    #else:


    try:
        df = pd.read_csv("multiqc/multiqc_data/multiqc_bowtie1.txt", sep='\t')
        rRNA = df.reads_aligned_percentage.mean()
        if rRNA < 10:   
            intro += f"<p>rRNA content (or contaminant provided) represents {rRNA}%, which is reasonable</p>"
        elif rRNA < 20:
            intro += f"<p>rRNA content (or contaminant provided) represents {rRNA}%, which is moderately low</p>"
        elif rRNA > 20:
            rRNA += f"<p>rRNA content (or contaminant provided) represents {rRNA}%, which is relatively high</p>"
        elif rRNA > 50:
            rRNA += f"<p>rRNA content (or contaminant provided) represents {rRNA}%, which is very high high</p>"
    except:
        pass

    intro+=    """
    <p>
    Differential gene expression analysis is not performed automatically with this pipeline. However, information, feature counts, and other materials can be found in the directory ./randiff. Most probably an analysis is present. If so, please open the report <a href="rnadiff/rnadiff.html">rnadiff</a>.
    </p>

    """
    s = SummaryModule2(data, intro)

    shell("chmod -R g+w .")
    shell("rm -rf rulegraph")
onerror:
    print("An error occurred. See message above.")


